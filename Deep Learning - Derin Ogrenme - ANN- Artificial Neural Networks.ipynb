{
 "cells": [
  {
   "cell_type": "raw",
   "id": "28814306",
   "metadata": {},
   "source": [
    "1- Derin ogrenmede Feature Engineering e gerek yok.\n",
    "2- Tensorflow kullaniyoruz. Keras- API Kullaniyoruz\n",
    "3- Tensor - cok boyutlu matrix Flow akis Google tarafindan gelistirildi. Rakip - Facebook Pytorch\n",
    "4- GPU(Ekran kartlari ile hesap yapmak daha hizli)\n",
    "5- Derin Ogrenme insan beyni ogrenme seklini kopyalar. Insan beyni nasil ogrenirse yapay senir aglari da oyle ogrenir.\n",
    "6- Noronlar arasinda gidip gelme islemine epoch denir\n",
    "7- Her norondan digerine bir agirlik aktarilir (katsayi) aktarilir\n",
    "8- Aktarma islemine Ativasyon fonksiyonu karar verir: ReLU, Softmax, Sigmoid\n",
    "9- Resimler cok buyuk oldugu icin parca-parca islenir buna batch-size denir.\n",
    "10- Resimler uzerinde calisiyorsaniz CNN kullanilir.\n",
    "11- Resim,Text,vieo uretme islemleri LSTM ile yapilir. (Long-Short Time Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d59d3",
   "metadata": {},
   "source": [
    "# Machine Learning with Deep Learning  1-Classification, 2- Regression, 3- Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c575d80",
   "metadata": {},
   "source": [
    "1- Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a16b41",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorflow) (4.4.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.50.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.6)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorflow) (21.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.13.0-py2.py3-none-any.whl (174 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\melih\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.13.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db257393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential #Siraya koymamizi sagliyacak\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7947a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedd5bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5acc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2bd8ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #Veride boslugumuz yok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1642a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #768 kadinin verisi var, 9 tane veri basligimiz var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904670e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c8a31ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e753882",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8]\n",
    "y=df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47346507",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,activation='relu')) # 8 tane sutun verimiz oldugu icin 8 ile basliyoruz.\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) #final karar eger evet hayir ise= sigmoid\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\") #adam= ogrenme hizi dusukse yukseltiyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60e14bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 0.9187 - accuracy: 0.4987\n",
      "Epoch 2/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6628\n",
      "Epoch 3/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.6667\n",
      "Epoch 4/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6732\n",
      "Epoch 5/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.6706\n",
      "Epoch 6/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6641\n",
      "Epoch 7/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6797\n",
      "Epoch 8/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.5981 - accuracy: 0.6810\n",
      "Epoch 9/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.5968 - accuracy: 0.6823\n",
      "Epoch 10/500\n",
      "77/77 [==============================] - 0s 961us/step - loss: 0.5936 - accuracy: 0.6758\n",
      "Epoch 11/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6862\n",
      "Epoch 12/500\n",
      "77/77 [==============================] - 0s 935us/step - loss: 0.5834 - accuracy: 0.7005\n",
      "Epoch 13/500\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.5848 - accuracy: 0.6979\n",
      "Epoch 14/500\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.5816 - accuracy: 0.7018\n",
      "Epoch 15/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6953\n",
      "Epoch 16/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.5728 - accuracy: 0.7044\n",
      "Epoch 17/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7161\n",
      "Epoch 18/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7148\n",
      "Epoch 19/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7135\n",
      "Epoch 20/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7122\n",
      "Epoch 21/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.5597 - accuracy: 0.7135\n",
      "Epoch 22/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7188\n",
      "Epoch 23/500\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.5579 - accuracy: 0.7174\n",
      "Epoch 24/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.5510 - accuracy: 0.7161\n",
      "Epoch 25/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.7240\n",
      "Epoch 26/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.5466 - accuracy: 0.7227\n",
      "Epoch 27/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7188\n",
      "Epoch 28/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.5449 - accuracy: 0.7227\n",
      "Epoch 29/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7148\n",
      "Epoch 30/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.5405 - accuracy: 0.7214\n",
      "Epoch 31/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.5404 - accuracy: 0.7292\n",
      "Epoch 32/500\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.5301 - accuracy: 0.7318\n",
      "Epoch 33/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7174\n",
      "Epoch 34/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7201\n",
      "Epoch 35/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7396\n",
      "Epoch 36/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7318\n",
      "Epoch 37/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7344\n",
      "Epoch 38/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7188\n",
      "Epoch 39/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7227\n",
      "Epoch 40/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7305\n",
      "Epoch 41/500\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.5096 - accuracy: 0.7487\n",
      "Epoch 42/500\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.5263 - accuracy: 0.7396\n",
      "Epoch 43/500\n",
      "77/77 [==============================] - 0s 967us/step - loss: 0.5203 - accuracy: 0.7422\n",
      "Epoch 44/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.5111 - accuracy: 0.7474\n",
      "Epoch 45/500\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.5146 - accuracy: 0.7422\n",
      "Epoch 46/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7461\n",
      "Epoch 47/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7409\n",
      "Epoch 48/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7448\n",
      "Epoch 49/500\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.5023 - accuracy: 0.7526\n",
      "Epoch 50/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7474\n",
      "Epoch 51/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7526\n",
      "Epoch 52/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7526\n",
      "Epoch 53/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7552\n",
      "Epoch 54/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7565\n",
      "Epoch 55/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7552\n",
      "Epoch 56/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7552\n",
      "Epoch 57/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7591\n",
      "Epoch 58/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7630\n",
      "Epoch 59/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7760\n",
      "Epoch 60/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7591\n",
      "Epoch 61/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7565\n",
      "Epoch 62/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7617\n",
      "Epoch 63/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7708\n",
      "Epoch 64/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7656\n",
      "Epoch 65/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7669\n",
      "Epoch 66/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7591\n",
      "Epoch 67/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7552\n",
      "Epoch 68/500\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.4617 - accuracy: 0.7604\n",
      "Epoch 69/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7617\n",
      "Epoch 70/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7786\n",
      "Epoch 71/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7669\n",
      "Epoch 72/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7734\n",
      "Epoch 73/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7839\n",
      "Epoch 74/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7812\n",
      "Epoch 75/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7865\n",
      "Epoch 76/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7930\n",
      "Epoch 77/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7721\n",
      "Epoch 78/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7917\n",
      "Epoch 79/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.4807 - accuracy: 0.7669\n",
      "Epoch 80/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7891\n",
      "Epoch 81/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7839\n",
      "Epoch 82/500\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.4470 - accuracy: 0.7943\n",
      "Epoch 83/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.4307 - accuracy: 0.7930\n",
      "Epoch 84/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.4348 - accuracy: 0.7904\n",
      "Epoch 85/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7904\n",
      "Epoch 86/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7826\n",
      "Epoch 87/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7865\n",
      "Epoch 88/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.8021\n",
      "Epoch 89/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8008\n",
      "Epoch 90/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.4349 - accuracy: 0.7930\n",
      "Epoch 91/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7904\n",
      "Epoch 92/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.4301 - accuracy: 0.7917\n",
      "Epoch 93/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7956\n",
      "Epoch 94/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8021\n",
      "Epoch 95/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8008\n",
      "Epoch 96/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.4149 - accuracy: 0.8047\n",
      "Epoch 97/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917\n",
      "Epoch 98/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.4356 - accuracy: 0.7891\n",
      "Epoch 99/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.7982\n",
      "Epoch 100/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8151\n",
      "Epoch 101/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8008\n",
      "Epoch 102/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8099\n",
      "Epoch 103/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7982\n",
      "Epoch 104/500\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.4122 - accuracy: 0.8034\n",
      "Epoch 105/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8073\n",
      "Epoch 106/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.7917\n",
      "Epoch 107/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8164\n",
      "Epoch 108/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.7982\n",
      "Epoch 109/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8073\n",
      "Epoch 110/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.7982\n",
      "Epoch 111/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4038 - accuracy: 0.8060\n",
      "Epoch 112/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8242\n",
      "Epoch 113/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8008\n",
      "Epoch 114/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8268\n",
      "Epoch 115/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.8151\n",
      "Epoch 116/500\n",
      "77/77 [==============================] - 0s 998us/step - loss: 0.4033 - accuracy: 0.8216\n",
      "Epoch 117/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8151\n",
      "Epoch 118/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8203\n",
      "Epoch 119/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.7982\n",
      "Epoch 120/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8190\n",
      "Epoch 121/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8112\n",
      "Epoch 122/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8151\n",
      "Epoch 123/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8021\n",
      "Epoch 124/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8073\n",
      "Epoch 125/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8151\n",
      "Epoch 126/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8164\n",
      "Epoch 127/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8164\n",
      "Epoch 128/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8229\n",
      "Epoch 129/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.3909 - accuracy: 0.8151\n",
      "Epoch 130/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.4073 - accuracy: 0.8138\n",
      "Epoch 131/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8203\n",
      "Epoch 132/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.3794 - accuracy: 0.8294\n",
      "Epoch 133/500\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.3740 - accuracy: 0.8307\n",
      "Epoch 134/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8294\n",
      "Epoch 135/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8164\n",
      "Epoch 136/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.3928 - accuracy: 0.8190\n",
      "Epoch 137/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8268\n",
      "Epoch 138/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8281\n",
      "Epoch 139/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8281\n",
      "Epoch 140/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8451\n",
      "Epoch 141/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8177\n",
      "Epoch 142/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.4037 - accuracy: 0.8034\n",
      "Epoch 143/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.3830 - accuracy: 0.8372\n",
      "Epoch 144/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.3775 - accuracy: 0.8320\n",
      "Epoch 145/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.3748 - accuracy: 0.8438\n",
      "Epoch 146/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8255\n",
      "Epoch 147/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8307\n",
      "Epoch 148/500\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.3929 - accuracy: 0.8281\n",
      "Epoch 149/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.3848 - accuracy: 0.8164\n",
      "Epoch 150/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8372\n",
      "Epoch 151/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.3762 - accuracy: 0.8190\n",
      "Epoch 152/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8294\n",
      "Epoch 153/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.3743 - accuracy: 0.8398\n",
      "Epoch 154/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8359\n",
      "Epoch 155/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.3735 - accuracy: 0.8307\n",
      "Epoch 156/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.3666 - accuracy: 0.8333\n",
      "Epoch 157/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8216\n",
      "Epoch 158/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8529\n",
      "Epoch 159/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8294\n",
      "Epoch 160/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8268\n",
      "Epoch 161/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8346\n",
      "Epoch 162/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8242\n",
      "Epoch 163/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8099\n",
      "Epoch 164/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8294\n",
      "Epoch 165/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8268\n",
      "Epoch 166/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.3677 - accuracy: 0.8333\n",
      "Epoch 167/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8229\n",
      "Epoch 168/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8255\n",
      "Epoch 169/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8385\n",
      "Epoch 170/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8477\n",
      "Epoch 171/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8359\n",
      "Epoch 172/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.3478 - accuracy: 0.8372\n",
      "Epoch 173/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.3598 - accuracy: 0.8424\n",
      "Epoch 174/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8464\n",
      "Epoch 175/500\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.3568 - accuracy: 0.8385\n",
      "Epoch 176/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.3431 - accuracy: 0.8529\n",
      "Epoch 177/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8320\n",
      "Epoch 178/500\n",
      "77/77 [==============================] - 0s 998us/step - loss: 0.3704 - accuracy: 0.8438\n",
      "Epoch 179/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8503\n",
      "Epoch 180/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8451\n",
      "Epoch 181/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8411\n",
      "Epoch 182/500\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.3345 - accuracy: 0.8555\n",
      "Epoch 183/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.3437 - accuracy: 0.8542\n",
      "Epoch 184/500\n",
      "77/77 [==============================] - 0s 967us/step - loss: 0.3558 - accuracy: 0.8385\n",
      "Epoch 185/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.3540 - accuracy: 0.8529\n",
      "Epoch 186/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8451\n",
      "Epoch 187/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.3398 - accuracy: 0.8568\n",
      "Epoch 188/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8086\n",
      "Epoch 189/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8281\n",
      "Epoch 190/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8411\n",
      "Epoch 191/500\n",
      "77/77 [==============================] - 0s 971us/step - loss: 0.3805 - accuracy: 0.8359\n",
      "Epoch 192/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8516\n",
      "Epoch 193/500\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.3331 - accuracy: 0.8646\n",
      "Epoch 194/500\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.3359 - accuracy: 0.8568\n",
      "Epoch 195/500\n",
      "77/77 [==============================] - 0s 964us/step - loss: 0.3564 - accuracy: 0.8438\n",
      "Epoch 196/500\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.3449 - accuracy: 0.8542\n",
      "Epoch 197/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.3589 - accuracy: 0.8320\n",
      "Epoch 198/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.3421 - accuracy: 0.8568\n",
      "Epoch 199/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8503\n",
      "Epoch 200/500\n",
      "77/77 [==============================] - 0s 964us/step - loss: 0.3361 - accuracy: 0.8503\n",
      "Epoch 201/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8659\n",
      "Epoch 202/500\n",
      "77/77 [==============================] - 0s 964us/step - loss: 0.3384 - accuracy: 0.8555\n",
      "Epoch 203/500\n",
      "77/77 [==============================] - 0s 978us/step - loss: 0.3287 - accuracy: 0.8659\n",
      "Epoch 204/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.3329 - accuracy: 0.8516\n",
      "Epoch 205/500\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.3529 - accuracy: 0.8438\n",
      "Epoch 206/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8503\n",
      "Epoch 207/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8646\n",
      "Epoch 208/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8477\n",
      "Epoch 209/500\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.3346 - accuracy: 0.8490\n",
      "Epoch 210/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8620\n",
      "Epoch 211/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.3355 - accuracy: 0.8438\n",
      "Epoch 212/500\n",
      "77/77 [==============================] - 0s 971us/step - loss: 0.3150 - accuracy: 0.8633\n",
      "Epoch 213/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8581\n",
      "Epoch 214/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8750\n",
      "Epoch 215/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8529\n",
      "Epoch 216/500\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.3208 - accuracy: 0.8620\n",
      "Epoch 217/500\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.3207 - accuracy: 0.8659\n",
      "Epoch 218/500\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.3215 - accuracy: 0.8581\n",
      "Epoch 219/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.3289 - accuracy: 0.8477\n",
      "Epoch 220/500\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.3632 - accuracy: 0.8320\n",
      "Epoch 221/500\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.3271 - accuracy: 0.8594\n",
      "Epoch 222/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8594\n",
      "Epoch 223/500\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.3212 - accuracy: 0.8685\n",
      "Epoch 224/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8503\n",
      "Epoch 225/500\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.3401 - accuracy: 0.8464\n",
      "Epoch 226/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.3303 - accuracy: 0.8620\n",
      "Epoch 227/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.3200 - accuracy: 0.8490\n",
      "Epoch 228/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8451\n",
      "Epoch 229/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8698\n",
      "Epoch 230/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.3350 - accuracy: 0.8503\n",
      "Epoch 231/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8594\n",
      "Epoch 232/500\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.3238 - accuracy: 0.8620\n",
      "Epoch 233/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.3091 - accuracy: 0.8659\n",
      "Epoch 234/500\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.3270 - accuracy: 0.8503\n",
      "Epoch 235/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8867\n",
      "Epoch 236/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.3049 - accuracy: 0.8698\n",
      "Epoch 237/500\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.3009 - accuracy: 0.8672\n",
      "Epoch 238/500\n",
      "77/77 [==============================] - 0s 971us/step - loss: 0.3525 - accuracy: 0.8372\n",
      "Epoch 239/500\n",
      "77/77 [==============================] - 0s 950us/step - loss: 0.3231 - accuracy: 0.8646\n",
      "Epoch 240/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.3102 - accuracy: 0.8711\n",
      "Epoch 241/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.3182 - accuracy: 0.8646\n",
      "Epoch 242/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8424\n",
      "Epoch 243/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8633\n",
      "Epoch 244/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3056 - accuracy: 0.8542\n",
      "Epoch 245/500\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.3003 - accuracy: 0.8698\n",
      "Epoch 246/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.2992 - accuracy: 0.8724\n",
      "Epoch 247/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2966 - accuracy: 0.8659\n",
      "Epoch 248/500\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.2993 - accuracy: 0.8828\n",
      "Epoch 249/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8607\n",
      "Epoch 250/500\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.3163 - accuracy: 0.8542\n",
      "Epoch 251/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.3046 - accuracy: 0.8685\n",
      "Epoch 252/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.3166 - accuracy: 0.8646\n",
      "Epoch 253/500\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.3058 - accuracy: 0.8633\n",
      "Epoch 254/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.3007 - accuracy: 0.8698\n",
      "Epoch 255/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.3175 - accuracy: 0.8607\n",
      "Epoch 256/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.8646\n",
      "Epoch 257/500\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.3173 - accuracy: 0.8581\n",
      "Epoch 258/500\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.2868 - accuracy: 0.8776\n",
      "Epoch 259/500\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.2924 - accuracy: 0.8737\n",
      "Epoch 260/500\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.3137 - accuracy: 0.8542\n",
      "Epoch 261/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8724\n",
      "Epoch 262/500\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.3027 - accuracy: 0.8685\n",
      "Epoch 263/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8659\n",
      "Epoch 264/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8737\n",
      "Epoch 265/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3120 - accuracy: 0.8698\n",
      "Epoch 266/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8698\n",
      "Epoch 267/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.8828\n",
      "Epoch 268/500\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.2927 - accuracy: 0.8763\n",
      "Epoch 269/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.2874 - accuracy: 0.8750\n",
      "Epoch 270/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2824 - accuracy: 0.8711\n",
      "Epoch 271/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8568\n",
      "Epoch 272/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8633\n",
      "Epoch 273/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8581\n",
      "Epoch 274/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8568\n",
      "Epoch 275/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.8750\n",
      "Epoch 276/500\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.2761 - accuracy: 0.8880\n",
      "Epoch 277/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.2913 - accuracy: 0.8672\n",
      "Epoch 278/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.8984\n",
      "Epoch 279/500\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.2816 - accuracy: 0.8763\n",
      "Epoch 280/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.8698\n",
      "Epoch 281/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.2825 - accuracy: 0.8828\n",
      "Epoch 282/500\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.3004 - accuracy: 0.8711\n",
      "Epoch 283/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.3082 - accuracy: 0.8672\n",
      "Epoch 284/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2923 - accuracy: 0.8815\n",
      "Epoch 285/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2973 - accuracy: 0.8737\n",
      "Epoch 286/500\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.2865 - accuracy: 0.8737\n",
      "Epoch 287/500\n",
      "77/77 [==============================] - 0s 967us/step - loss: 0.2847 - accuracy: 0.8854\n",
      "Epoch 288/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8815\n",
      "Epoch 289/500\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.2809 - accuracy: 0.8763\n",
      "Epoch 290/500\n",
      "77/77 [==============================] - 0s 994us/step - loss: 0.2800 - accuracy: 0.8815\n",
      "Epoch 291/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8672\n",
      "Epoch 292/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8672\n",
      "Epoch 293/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8542\n",
      "Epoch 294/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8542\n",
      "Epoch 295/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8789\n",
      "Epoch 296/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8815\n",
      "Epoch 297/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2654 - accuracy: 0.8841\n",
      "Epoch 298/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2956 - accuracy: 0.8776\n",
      "Epoch 299/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.8776\n",
      "Epoch 300/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.8867\n",
      "Epoch 301/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.8828\n",
      "Epoch 302/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8815\n",
      "Epoch 303/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8828\n",
      "Epoch 304/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2679 - accuracy: 0.8932\n",
      "Epoch 305/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8724\n",
      "Epoch 306/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.8854\n",
      "Epoch 307/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8867\n",
      "Epoch 308/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.8932\n",
      "Epoch 309/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.8789\n",
      "Epoch 310/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8763\n",
      "Epoch 311/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2641 - accuracy: 0.8880\n",
      "Epoch 312/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.8919\n",
      "Epoch 313/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.8919\n",
      "Epoch 314/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.8841\n",
      "Epoch 315/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8698\n",
      "Epoch 316/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.8893\n",
      "Epoch 317/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8763\n",
      "Epoch 318/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8984\n",
      "Epoch 319/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.8971\n",
      "Epoch 320/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.8880\n",
      "Epoch 321/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2657 - accuracy: 0.8854\n",
      "Epoch 322/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8802\n",
      "Epoch 323/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8633\n",
      "Epoch 324/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.3038 - accuracy: 0.8711\n",
      "Epoch 325/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.8906\n",
      "Epoch 326/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8750\n",
      "Epoch 327/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8867\n",
      "Epoch 328/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.8763\n",
      "Epoch 329/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8880\n",
      "Epoch 330/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9010\n",
      "Epoch 331/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.8906\n",
      "Epoch 332/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2502 - accuracy: 0.8919\n",
      "Epoch 333/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2600 - accuracy: 0.8789\n",
      "Epoch 334/500\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.2632 - accuracy: 0.8893\n",
      "Epoch 335/500\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.2714 - accuracy: 0.8919\n",
      "Epoch 336/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8685\n",
      "Epoch 337/500\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.2636 - accuracy: 0.8841\n",
      "Epoch 338/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.8854\n",
      "Epoch 339/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.2664 - accuracy: 0.8750\n",
      "Epoch 340/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.8776\n",
      "Epoch 341/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.2446 - accuracy: 0.8958\n",
      "Epoch 342/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.2447 - accuracy: 0.8945\n",
      "Epoch 343/500\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.2428 - accuracy: 0.8958\n",
      "Epoch 344/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.8958\n",
      "Epoch 345/500\n",
      "77/77 [==============================] - 0s 999us/step - loss: 0.2514 - accuracy: 0.8867\n",
      "Epoch 346/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.8815\n",
      "Epoch 347/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.8828\n",
      "Epoch 348/500\n",
      "77/77 [==============================] - 0s 967us/step - loss: 0.2804 - accuracy: 0.8776\n",
      "Epoch 349/500\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.2395 - accuracy: 0.8919\n",
      "Epoch 350/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.8971\n",
      "Epoch 351/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.8984\n",
      "Epoch 352/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8971\n",
      "Epoch 353/500\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.2805 - accuracy: 0.8802\n",
      "Epoch 354/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8880\n",
      "Epoch 355/500\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.2609 - accuracy: 0.8867\n",
      "Epoch 356/500\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.2694 - accuracy: 0.8789\n",
      "Epoch 357/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.2718 - accuracy: 0.8750\n",
      "Epoch 358/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.2359 - accuracy: 0.9010\n",
      "Epoch 359/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2591 - accuracy: 0.8958\n",
      "Epoch 360/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2555 - accuracy: 0.8880\n",
      "Epoch 361/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8945\n",
      "Epoch 362/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.8997\n",
      "Epoch 363/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.8880\n",
      "Epoch 364/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.9062\n",
      "Epoch 365/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.8880\n",
      "Epoch 366/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.8945\n",
      "Epoch 367/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.2415 - accuracy: 0.9023\n",
      "Epoch 368/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.9036\n",
      "Epoch 369/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.8880\n",
      "Epoch 370/500\n",
      "77/77 [==============================] - 0s 992us/step - loss: 0.3619 - accuracy: 0.8568\n",
      "Epoch 371/500\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.3063 - accuracy: 0.8698\n",
      "Epoch 372/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8802\n",
      "Epoch 373/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8828\n",
      "Epoch 374/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.8828\n",
      "Epoch 375/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.8919\n",
      "Epoch 376/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.8932\n",
      "Epoch 377/500\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.2290 - accuracy: 0.8932\n",
      "Epoch 378/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.8997\n",
      "Epoch 379/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2893 - accuracy: 0.8776\n",
      "Epoch 380/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.2373 - accuracy: 0.8932\n",
      "Epoch 381/500\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.2251 - accuracy: 0.9128\n",
      "Epoch 382/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9049\n",
      "Epoch 383/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8919\n",
      "Epoch 384/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.2497 - accuracy: 0.8919\n",
      "Epoch 385/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.8802\n",
      "Epoch 386/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.8945\n",
      "Epoch 387/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2472 - accuracy: 0.8958\n",
      "Epoch 388/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.8958\n",
      "Epoch 389/500\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.2310 - accuracy: 0.9023\n",
      "Epoch 390/500\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.2390 - accuracy: 0.8932\n",
      "Epoch 391/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2264 - accuracy: 0.9141\n",
      "Epoch 392/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.8906\n",
      "Epoch 393/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2566 - accuracy: 0.8971\n",
      "Epoch 394/500\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.2904 - accuracy: 0.8685\n",
      "Epoch 395/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.2496 - accuracy: 0.8945\n",
      "Epoch 396/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.2363 - accuracy: 0.8984\n",
      "Epoch 397/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2574 - accuracy: 0.8828\n",
      "Epoch 398/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9036\n",
      "Epoch 399/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.8958\n",
      "Epoch 400/500\n",
      "77/77 [==============================] - 0s 973us/step - loss: 0.2348 - accuracy: 0.9036\n",
      "Epoch 401/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9023\n",
      "Epoch 402/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8828\n",
      "Epoch 403/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.8841\n",
      "Epoch 404/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.8971\n",
      "Epoch 405/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.8984\n",
      "Epoch 406/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2185 - accuracy: 0.8997\n",
      "Epoch 407/500\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.2472 - accuracy: 0.9062\n",
      "Epoch 408/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.8919\n",
      "Epoch 409/500\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.2588 - accuracy: 0.8932\n",
      "Epoch 410/500\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.2616 - accuracy: 0.8854\n",
      "Epoch 411/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.2358 - accuracy: 0.9076\n",
      "Epoch 412/500\n",
      "77/77 [==============================] - 0s 961us/step - loss: 0.2172 - accuracy: 0.8997\n",
      "Epoch 413/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.8867\n",
      "Epoch 414/500\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.2486 - accuracy: 0.8932\n",
      "Epoch 415/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2820 - accuracy: 0.8828\n",
      "Epoch 416/500\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2842 - accuracy: 0.8776\n",
      "Epoch 417/500\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.2443 - accuracy: 0.8958\n",
      "Epoch 418/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9036\n",
      "Epoch 419/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.8997\n",
      "Epoch 420/500\n",
      "77/77 [==============================] - 0s 961us/step - loss: 0.2456 - accuracy: 0.8945\n",
      "Epoch 421/500\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.2437 - accuracy: 0.8932\n",
      "Epoch 422/500\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.2437 - accuracy: 0.8841\n",
      "Epoch 423/500\n",
      "77/77 [==============================] - 0s 967us/step - loss: 0.2494 - accuracy: 0.8867\n",
      "Epoch 424/500\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.2595 - accuracy: 0.8867\n",
      "Epoch 425/500\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.2231 - accuracy: 0.9102\n",
      "Epoch 426/500\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.2149 - accuracy: 0.9141\n",
      "Epoch 427/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.2680 - accuracy: 0.8919\n",
      "Epoch 428/500\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.2307 - accuracy: 0.8984\n",
      "Epoch 429/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.8958\n",
      "Epoch 430/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 0.8841\n",
      "Epoch 431/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.2301 - accuracy: 0.9036\n",
      "Epoch 432/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9049\n",
      "Epoch 433/500\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.2140 - accuracy: 0.9049\n",
      "Epoch 434/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.2482 - accuracy: 0.8815\n",
      "Epoch 435/500\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.2240 - accuracy: 0.9076\n",
      "Epoch 436/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.2670 - accuracy: 0.8867\n",
      "Epoch 437/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.9062\n",
      "Epoch 438/500\n",
      "77/77 [==============================] - 0s 964us/step - loss: 0.2254 - accuracy: 0.9049\n",
      "Epoch 439/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.2190 - accuracy: 0.9036\n",
      "Epoch 440/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2245 - accuracy: 0.8997\n",
      "Epoch 441/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9010\n",
      "Epoch 442/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9036\n",
      "Epoch 443/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.8919\n",
      "Epoch 444/500\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.2168 - accuracy: 0.9089\n",
      "Epoch 445/500\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.2268 - accuracy: 0.8945\n",
      "Epoch 446/500\n",
      "77/77 [==============================] - 0s 944us/step - loss: 0.2722 - accuracy: 0.8789\n",
      "Epoch 447/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.8802\n",
      "Epoch 448/500\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.2491 - accuracy: 0.8867\n",
      "Epoch 449/500\n",
      "77/77 [==============================] - 0s 935us/step - loss: 0.3089 - accuracy: 0.8737\n",
      "Epoch 450/500\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.2881 - accuracy: 0.8672\n",
      "Epoch 451/500\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.2626 - accuracy: 0.8971\n",
      "Epoch 452/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.2282 - accuracy: 0.9062\n",
      "Epoch 453/500\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.2603 - accuracy: 0.8854\n",
      "Epoch 454/500\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.2258 - accuracy: 0.9023\n",
      "Epoch 455/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.2487 - accuracy: 0.8945\n",
      "Epoch 456/500\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.2183 - accuracy: 0.9076\n",
      "Epoch 457/500\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.2102 - accuracy: 0.9180\n",
      "Epoch 458/500\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.2320 - accuracy: 0.8945\n",
      "Epoch 459/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.8997\n",
      "Epoch 460/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9193\n",
      "Epoch 461/500\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.2202 - accuracy: 0.8984\n",
      "Epoch 462/500\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.2085 - accuracy: 0.9141\n",
      "Epoch 463/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9010\n",
      "Epoch 464/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.8971\n",
      "Epoch 465/500\n",
      "77/77 [==============================] - 0s 961us/step - loss: 0.2363 - accuracy: 0.9049\n",
      "Epoch 466/500\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.2326 - accuracy: 0.9076\n",
      "Epoch 467/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8906\n",
      "Epoch 468/500\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.2482 - accuracy: 0.8932\n",
      "Epoch 469/500\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.2397 - accuracy: 0.9062\n",
      "Epoch 470/500\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.2258 - accuracy: 0.9023\n",
      "Epoch 471/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.2382 - accuracy: 0.8880\n",
      "Epoch 472/500\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.2293 - accuracy: 0.9089\n",
      "Epoch 473/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.8932\n",
      "Epoch 474/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8685\n",
      "Epoch 475/500\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.2765 - accuracy: 0.8867\n",
      "Epoch 476/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.9023\n",
      "Epoch 477/500\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.2237 - accuracy: 0.9102\n",
      "Epoch 478/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9062\n",
      "Epoch 479/500\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.2261 - accuracy: 0.9089\n",
      "Epoch 480/500\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.2171 - accuracy: 0.9141\n",
      "Epoch 481/500\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.2161 - accuracy: 0.9076\n",
      "Epoch 482/500\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.2559 - accuracy: 0.9023\n",
      "Epoch 483/500\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.1969 - accuracy: 0.9206\n",
      "Epoch 484/500\n",
      "77/77 [==============================] - 0s 942us/step - loss: 0.1997 - accuracy: 0.9076\n",
      "Epoch 485/500\n",
      "77/77 [==============================] - 0s 962us/step - loss: 0.2141 - accuracy: 0.9062\n",
      "Epoch 486/500\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.2191 - accuracy: 0.9049\n",
      "Epoch 487/500\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.2056 - accuracy: 0.9089\n",
      "Epoch 488/500\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.2108 - accuracy: 0.9128\n",
      "Epoch 489/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9128\n",
      "Epoch 490/500\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.2139 - accuracy: 0.9115\n",
      "Epoch 491/500\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.2283 - accuracy: 0.9062\n",
      "Epoch 492/500\n",
      "77/77 [==============================] - 0s 935us/step - loss: 0.1953 - accuracy: 0.9167\n",
      "Epoch 493/500\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.2282 - accuracy: 0.9049\n",
      "Epoch 494/500\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.2907 - accuracy: 0.8789\n",
      "Epoch 495/500\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.3396 - accuracy: 0.8529\n",
      "Epoch 496/500\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.2590 - accuracy: 0.8867\n",
      "Epoch 497/500\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.2274 - accuracy: 0.8984\n",
      "Epoch 498/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.2218 - accuracy: 0.9062\n",
      "Epoch 499/500\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.2255 - accuracy: 0.8997\n",
      "Epoch 500/500\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.2370 - accuracy: 0.9076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f11be94f40>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y, epochs=500, batch_size=10, verbose=1) #Accuracy 90 with epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df3e8f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 16)                144       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,361\n",
      "Trainable params: 1,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df42a4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 867us/step - loss: 0.1970 - accuracy: 0.9206\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6979db60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19702468812465668"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0] #loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56f12cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205729365348816"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] #accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b472e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping - 150 de durmasi gerekirse  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "660d835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9528 - val_loss: 0.1325 - val_accuracy: 0.9481\n",
      "Epoch 2/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9088 - val_loss: 0.2552 - val_accuracy: 0.9156\n",
      "Epoch 3/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9007 - val_loss: 0.1738 - val_accuracy: 0.9091\n",
      "Epoch 4/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9218 - val_loss: 0.1719 - val_accuracy: 0.9351\n",
      "Epoch 5/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9430 - val_loss: 0.1561 - val_accuracy: 0.9610\n",
      "Epoch 6/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9479 - val_loss: 0.1175 - val_accuracy: 0.9740\n",
      "Epoch 7/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9397 - val_loss: 0.1486 - val_accuracy: 0.9675\n",
      "Epoch 8/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.9235 - val_loss: 0.1902 - val_accuracy: 0.9351\n",
      "Epoch 9/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9332 - val_loss: 0.1972 - val_accuracy: 0.9351\n",
      "Epoch 10/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9511 - val_loss: 0.1863 - val_accuracy: 0.9221\n",
      "Epoch 11/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8420 - val_loss: 0.3857 - val_accuracy: 0.8701\n",
      "Epoch 12/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.8909 - val_loss: 0.2427 - val_accuracy: 0.9091\n",
      "Epoch 13/500\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9169 - val_loss: 0.1969 - val_accuracy: 0.9286\n",
      "Epoch 14/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.9055 - val_loss: 0.3581 - val_accuracy: 0.8701\n",
      "Epoch 15/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8648 - val_loss: 0.4434 - val_accuracy: 0.8312\n",
      "Epoch 16/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8713 - val_loss: 0.2612 - val_accuracy: 0.8766\n",
      "Epoch 17/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9251 - val_loss: 0.1926 - val_accuracy: 0.9286\n",
      "Epoch 18/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9430 - val_loss: 0.2176 - val_accuracy: 0.9416\n",
      "Epoch 19/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9463 - val_loss: 0.1752 - val_accuracy: 0.9286\n",
      "Epoch 20/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9430 - val_loss: 0.2080 - val_accuracy: 0.9221\n",
      "Epoch 21/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9414 - val_loss: 0.1864 - val_accuracy: 0.9091\n",
      "Epoch 22/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9511 - val_loss: 0.1715 - val_accuracy: 0.9481\n",
      "Epoch 23/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9528 - val_loss: 0.1967 - val_accuracy: 0.9286\n",
      "Epoch 24/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9528 - val_loss: 0.1781 - val_accuracy: 0.9091\n",
      "Epoch 25/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9577 - val_loss: 0.1624 - val_accuracy: 0.9481\n",
      "Epoch 26/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9560 - val_loss: 0.2086 - val_accuracy: 0.9091\n",
      "Epoch 27/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9463 - val_loss: 0.2130 - val_accuracy: 0.8961\n",
      "Epoch 28/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9463 - val_loss: 0.2179 - val_accuracy: 0.9351\n",
      "Epoch 29/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9560 - val_loss: 0.2058 - val_accuracy: 0.9416\n",
      "Epoch 30/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9495 - val_loss: 0.2248 - val_accuracy: 0.9156\n",
      "Epoch 31/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9528 - val_loss: 0.2103 - val_accuracy: 0.9416\n",
      "Epoch 32/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9414 - val_loss: 0.2488 - val_accuracy: 0.9091\n",
      "Epoch 33/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9544 - val_loss: 0.1806 - val_accuracy: 0.9351\n",
      "Epoch 34/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9463 - val_loss: 0.2179 - val_accuracy: 0.9156\n",
      "Epoch 35/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9316 - val_loss: 0.3898 - val_accuracy: 0.8442\n",
      "Epoch 36/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9365 - val_loss: 0.3192 - val_accuracy: 0.9286\n",
      "Epoch 37/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9235 - val_loss: 0.2700 - val_accuracy: 0.8701\n",
      "Epoch 38/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9104 - val_loss: 0.4340 - val_accuracy: 0.8442\n",
      "Epoch 39/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2621 - accuracy: 0.8876 - val_loss: 0.3583 - val_accuracy: 0.8506\n",
      "Epoch 40/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9365 - val_loss: 0.2748 - val_accuracy: 0.9091\n",
      "Epoch 41/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9446 - val_loss: 0.3858 - val_accuracy: 0.8961\n",
      "Epoch 42/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9137 - val_loss: 0.3616 - val_accuracy: 0.8571\n",
      "Epoch 43/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9235 - val_loss: 0.2568 - val_accuracy: 0.9091\n",
      "Epoch 44/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9414 - val_loss: 0.2062 - val_accuracy: 0.9351\n",
      "Epoch 45/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9544 - val_loss: 0.2411 - val_accuracy: 0.9351\n",
      "Epoch 46/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9414 - val_loss: 0.2211 - val_accuracy: 0.9156\n",
      "Epoch 47/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9381 - val_loss: 0.2173 - val_accuracy: 0.8896\n",
      "Epoch 48/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9511 - val_loss: 0.2391 - val_accuracy: 0.8961\n",
      "Epoch 49/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9479 - val_loss: 0.2217 - val_accuracy: 0.9286\n",
      "Epoch 50/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9479 - val_loss: 0.2114 - val_accuracy: 0.9091\n",
      "Epoch 51/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9609 - val_loss: 0.2255 - val_accuracy: 0.9221\n",
      "Epoch 52/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9544 - val_loss: 0.2195 - val_accuracy: 0.9416\n",
      "Epoch 53/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9593 - val_loss: 0.2394 - val_accuracy: 0.9221\n",
      "Epoch 54/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9430 - val_loss: 0.3923 - val_accuracy: 0.8701\n",
      "Epoch 55/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9088 - val_loss: 0.2757 - val_accuracy: 0.8961\n",
      "Epoch 56/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9251 - val_loss: 0.3640 - val_accuracy: 0.8636\n",
      "Epoch 57/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9153 - val_loss: 0.3052 - val_accuracy: 0.9026\n",
      "Epoch 58/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9218 - val_loss: 0.4782 - val_accuracy: 0.8117\n",
      "Epoch 59/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.8941 - val_loss: 0.4676 - val_accuracy: 0.8506\n",
      "Epoch 60/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9153 - val_loss: 0.2950 - val_accuracy: 0.8961\n",
      "Epoch 61/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9332 - val_loss: 0.2608 - val_accuracy: 0.8961\n",
      "Epoch 62/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9137 - val_loss: 0.4130 - val_accuracy: 0.8636\n",
      "Epoch 63/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.8811 - val_loss: 0.4674 - val_accuracy: 0.8247\n",
      "Epoch 64/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.8974 - val_loss: 0.3137 - val_accuracy: 0.8701\n",
      "Epoch 65/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9283 - val_loss: 0.3271 - val_accuracy: 0.8701\n",
      "Epoch 66/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9381 - val_loss: 0.2799 - val_accuracy: 0.8896\n",
      "Epoch 67/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9446 - val_loss: 0.2752 - val_accuracy: 0.8961\n",
      "Epoch 68/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9479 - val_loss: 0.2458 - val_accuracy: 0.8896\n",
      "Epoch 69/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9463 - val_loss: 0.2640 - val_accuracy: 0.9156\n",
      "Epoch 70/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9479 - val_loss: 0.3183 - val_accuracy: 0.8831\n",
      "Epoch 71/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9577 - val_loss: 0.3078 - val_accuracy: 0.8961\n",
      "Epoch 72/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9577 - val_loss: 0.2921 - val_accuracy: 0.8831\n",
      "Epoch 73/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9495 - val_loss: 0.2535 - val_accuracy: 0.9221\n",
      "Epoch 74/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9495 - val_loss: 0.2998 - val_accuracy: 0.9091\n",
      "Epoch 75/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9430 - val_loss: 0.2529 - val_accuracy: 0.9091\n",
      "Epoch 76/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9511 - val_loss: 0.2782 - val_accuracy: 0.9026\n",
      "Epoch 77/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9446 - val_loss: 0.2707 - val_accuracy: 0.8766\n",
      "Epoch 78/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9495 - val_loss: 0.3243 - val_accuracy: 0.8961\n",
      "Epoch 79/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9463 - val_loss: 0.3349 - val_accuracy: 0.8831\n",
      "Epoch 80/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9463 - val_loss: 0.3057 - val_accuracy: 0.8961\n",
      "Epoch 81/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9365 - val_loss: 0.3136 - val_accuracy: 0.8896\n",
      "Epoch 82/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9430 - val_loss: 0.3425 - val_accuracy: 0.8636\n",
      "Epoch 83/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9397 - val_loss: 0.3250 - val_accuracy: 0.8831\n",
      "Epoch 84/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9218 - val_loss: 0.3169 - val_accuracy: 0.9026\n",
      "Epoch 85/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9316 - val_loss: 0.2126 - val_accuracy: 0.9091\n",
      "Epoch 86/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9332 - val_loss: 0.4291 - val_accuracy: 0.8701\n",
      "Epoch 87/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9397 - val_loss: 0.3253 - val_accuracy: 0.8701\n",
      "Epoch 88/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9316 - val_loss: 0.4081 - val_accuracy: 0.8701\n",
      "Epoch 89/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9137 - val_loss: 0.3253 - val_accuracy: 0.8766\n",
      "Epoch 90/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9023 - val_loss: 0.4173 - val_accuracy: 0.8571\n",
      "Epoch 91/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9072 - val_loss: 0.5343 - val_accuracy: 0.8442\n",
      "Epoch 92/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9202 - val_loss: 0.3718 - val_accuracy: 0.8636\n",
      "Epoch 93/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9397 - val_loss: 0.3077 - val_accuracy: 0.8506\n",
      "Epoch 94/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9430 - val_loss: 0.3636 - val_accuracy: 0.8636\n",
      "Epoch 95/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9560 - val_loss: 0.2979 - val_accuracy: 0.8701\n",
      "Epoch 96/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9479 - val_loss: 0.3101 - val_accuracy: 0.8896\n",
      "Epoch 97/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9463 - val_loss: 0.2690 - val_accuracy: 0.9091\n",
      "Epoch 98/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9560 - val_loss: 0.3111 - val_accuracy: 0.8961\n",
      "Epoch 99/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9528 - val_loss: 0.3720 - val_accuracy: 0.8701\n",
      "Epoch 100/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9544 - val_loss: 0.2652 - val_accuracy: 0.8896\n",
      "Epoch 101/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9430 - val_loss: 0.2809 - val_accuracy: 0.9026\n",
      "Epoch 102/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9397 - val_loss: 0.3348 - val_accuracy: 0.8506\n",
      "Epoch 103/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9332 - val_loss: 0.4456 - val_accuracy: 0.8312\n",
      "Epoch 104/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8844 - val_loss: 0.3529 - val_accuracy: 0.8701\n",
      "Epoch 105/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9137 - val_loss: 0.3873 - val_accuracy: 0.8636\n",
      "Epoch 106/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9316 - val_loss: 0.4374 - val_accuracy: 0.8636\n",
      "Epoch 107/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9202 - val_loss: 0.4793 - val_accuracy: 0.8442\n",
      "Epoch 108/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9007 - val_loss: 0.4134 - val_accuracy: 0.8117\n",
      "Epoch 109/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.9218 - val_loss: 0.4392 - val_accuracy: 0.8506\n",
      "Epoch 110/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9332 - val_loss: 0.4008 - val_accuracy: 0.8636\n",
      "Epoch 111/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9283 - val_loss: 0.4134 - val_accuracy: 0.8636\n",
      "Epoch 112/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9430 - val_loss: 0.3580 - val_accuracy: 0.8636\n",
      "Epoch 113/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9300 - val_loss: 0.4580 - val_accuracy: 0.8377\n",
      "Epoch 114/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9463 - val_loss: 0.3423 - val_accuracy: 0.8571\n",
      "Epoch 115/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9560 - val_loss: 0.3213 - val_accuracy: 0.8961\n",
      "Epoch 116/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9560 - val_loss: 0.3834 - val_accuracy: 0.8377\n",
      "Epoch 117/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9528 - val_loss: 0.3593 - val_accuracy: 0.8766\n",
      "Epoch 118/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9560 - val_loss: 0.3663 - val_accuracy: 0.8701\n",
      "Epoch 119/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9544 - val_loss: 0.4014 - val_accuracy: 0.8831\n",
      "Epoch 120/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9560 - val_loss: 0.3373 - val_accuracy: 0.8831\n",
      "Epoch 121/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9495 - val_loss: 0.3519 - val_accuracy: 0.8766\n",
      "Epoch 122/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9528 - val_loss: 0.3080 - val_accuracy: 0.8961\n",
      "Epoch 123/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9544 - val_loss: 0.3769 - val_accuracy: 0.8896\n",
      "Epoch 124/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9609 - val_loss: 0.3836 - val_accuracy: 0.8831\n",
      "Epoch 125/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9495 - val_loss: 0.4747 - val_accuracy: 0.8636\n",
      "Epoch 126/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9104 - val_loss: 0.4512 - val_accuracy: 0.8377\n",
      "Epoch 127/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8925 - val_loss: 0.4197 - val_accuracy: 0.8312\n",
      "Epoch 128/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.8909 - val_loss: 0.3551 - val_accuracy: 0.8442\n",
      "Epoch 129/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9251 - val_loss: 0.3633 - val_accuracy: 0.8506\n",
      "Epoch 130/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9349 - val_loss: 0.3741 - val_accuracy: 0.8247\n",
      "Epoch 131/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9397 - val_loss: 0.4757 - val_accuracy: 0.8312\n",
      "Epoch 132/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9283 - val_loss: 0.4527 - val_accuracy: 0.8636\n",
      "Epoch 133/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.9137 - val_loss: 0.3815 - val_accuracy: 0.8506\n",
      "Epoch 134/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9430 - val_loss: 0.3696 - val_accuracy: 0.8766\n",
      "Epoch 135/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9560 - val_loss: 0.3754 - val_accuracy: 0.8636\n",
      "Epoch 136/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9479 - val_loss: 0.3980 - val_accuracy: 0.8896\n",
      "Epoch 137/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9593 - val_loss: 0.3663 - val_accuracy: 0.8636\n",
      "Epoch 138/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9511 - val_loss: 0.3697 - val_accuracy: 0.8701\n",
      "Epoch 139/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9495 - val_loss: 0.3721 - val_accuracy: 0.8766\n",
      "Epoch 140/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9349 - val_loss: 0.4192 - val_accuracy: 0.8506\n",
      "Epoch 141/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9365 - val_loss: 0.4504 - val_accuracy: 0.8442\n",
      "Epoch 142/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9381 - val_loss: 0.4134 - val_accuracy: 0.8831\n",
      "Epoch 143/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9495 - val_loss: 0.4347 - val_accuracy: 0.8506\n",
      "Epoch 144/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9397 - val_loss: 0.4205 - val_accuracy: 0.8571\n",
      "Epoch 145/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9479 - val_loss: 0.5423 - val_accuracy: 0.7987\n",
      "Epoch 146/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9479 - val_loss: 0.3851 - val_accuracy: 0.8766\n",
      "Epoch 147/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9560 - val_loss: 0.3807 - val_accuracy: 0.8636\n",
      "Epoch 148/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9528 - val_loss: 0.4205 - val_accuracy: 0.8636\n",
      "Epoch 149/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9479 - val_loss: 0.3563 - val_accuracy: 0.8961\n",
      "Epoch 150/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9544 - val_loss: 0.4135 - val_accuracy: 0.8766\n",
      "Epoch 151/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9528 - val_loss: 0.4155 - val_accuracy: 0.8896\n",
      "Epoch 152/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.9446 - val_loss: 0.3553 - val_accuracy: 0.8701\n",
      "Epoch 153/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9463 - val_loss: 0.4400 - val_accuracy: 0.8506\n",
      "Epoch 154/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9088 - val_loss: 0.6679 - val_accuracy: 0.7922\n",
      "Epoch 155/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8974 - val_loss: 0.4880 - val_accuracy: 0.8377\n",
      "Epoch 156/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9300 - val_loss: 0.4629 - val_accuracy: 0.8182\n",
      "Epoch 157/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9267 - val_loss: 0.4778 - val_accuracy: 0.8117\n",
      "Epoch 158/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9235 - val_loss: 0.3834 - val_accuracy: 0.8571\n",
      "Epoch 159/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9153 - val_loss: 0.4841 - val_accuracy: 0.8052\n",
      "Epoch 160/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9414 - val_loss: 0.3623 - val_accuracy: 0.8442\n",
      "Epoch 161/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9267 - val_loss: 0.3828 - val_accuracy: 0.8701\n",
      "Epoch 162/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9414 - val_loss: 0.3843 - val_accuracy: 0.8636\n",
      "Epoch 163/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9316 - val_loss: 0.4218 - val_accuracy: 0.8701\n",
      "Epoch 164/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9169 - val_loss: 0.4342 - val_accuracy: 0.8636\n",
      "Epoch 165/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9169 - val_loss: 0.4424 - val_accuracy: 0.8571\n",
      "Epoch 166/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9316 - val_loss: 0.4829 - val_accuracy: 0.8701\n",
      "Epoch 167/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9463 - val_loss: 0.4194 - val_accuracy: 0.8506\n",
      "Epoch 168/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9463 - val_loss: 0.4390 - val_accuracy: 0.8701\n",
      "Epoch 169/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9446 - val_loss: 0.4015 - val_accuracy: 0.8766\n",
      "Epoch 170/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9430 - val_loss: 0.4429 - val_accuracy: 0.8571\n",
      "Epoch 171/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9430 - val_loss: 0.4649 - val_accuracy: 0.8312\n",
      "Epoch 172/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9300 - val_loss: 0.3937 - val_accuracy: 0.8701\n",
      "Epoch 173/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9495 - val_loss: 0.4255 - val_accuracy: 0.8766\n",
      "Epoch 174/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9479 - val_loss: 0.4069 - val_accuracy: 0.8831\n",
      "Epoch 175/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9642 - val_loss: 0.3856 - val_accuracy: 0.8636\n",
      "Epoch 176/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9609 - val_loss: 0.4445 - val_accuracy: 0.8636\n",
      "Epoch 177/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9593 - val_loss: 0.3759 - val_accuracy: 0.8961\n",
      "Epoch 178/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9528 - val_loss: 0.3688 - val_accuracy: 0.8961\n",
      "Epoch 179/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9593 - val_loss: 0.3489 - val_accuracy: 0.8831\n",
      "Epoch 180/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9577 - val_loss: 0.4085 - val_accuracy: 0.8896\n",
      "Epoch 181/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9479 - val_loss: 0.3678 - val_accuracy: 0.8896\n",
      "Epoch 182/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9495 - val_loss: 0.4200 - val_accuracy: 0.8571\n",
      "Epoch 183/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9430 - val_loss: 0.5929 - val_accuracy: 0.8571\n",
      "Epoch 184/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9072 - val_loss: 0.4620 - val_accuracy: 0.8571\n",
      "Epoch 185/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9316 - val_loss: 0.3761 - val_accuracy: 0.8701\n",
      "Epoch 186/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9479 - val_loss: 0.3676 - val_accuracy: 0.8701\n",
      "Epoch 187/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9479 - val_loss: 0.3526 - val_accuracy: 0.8636\n",
      "Epoch 188/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9560 - val_loss: 0.4304 - val_accuracy: 0.8701\n",
      "Epoch 189/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9365 - val_loss: 0.4162 - val_accuracy: 0.8831\n",
      "Epoch 190/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9430 - val_loss: 0.4010 - val_accuracy: 0.8377\n",
      "Epoch 191/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9414 - val_loss: 0.6222 - val_accuracy: 0.8247\n",
      "Epoch 192/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8779 - val_loss: 0.5547 - val_accuracy: 0.8182\n",
      "Epoch 193/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9316 - val_loss: 0.4009 - val_accuracy: 0.8701\n",
      "Epoch 194/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9479 - val_loss: 0.3723 - val_accuracy: 0.8442\n",
      "Epoch 195/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9495 - val_loss: 0.3696 - val_accuracy: 0.8831\n",
      "Epoch 196/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9463 - val_loss: 0.3701 - val_accuracy: 0.8766\n",
      "Epoch 197/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9316 - val_loss: 0.4821 - val_accuracy: 0.8377\n",
      "Epoch 198/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9397 - val_loss: 0.4606 - val_accuracy: 0.8247\n",
      "Epoch 199/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9511 - val_loss: 0.3368 - val_accuracy: 0.8831\n",
      "Epoch 200/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9463 - val_loss: 0.3781 - val_accuracy: 0.8571\n",
      "Epoch 201/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9593 - val_loss: 0.3388 - val_accuracy: 0.8831\n",
      "Epoch 202/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9528 - val_loss: 0.4039 - val_accuracy: 0.8896\n",
      "Epoch 203/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9169 - val_loss: 0.4732 - val_accuracy: 0.8701\n",
      "Epoch 204/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9446 - val_loss: 0.4307 - val_accuracy: 0.8506\n",
      "Epoch 205/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9300 - val_loss: 0.6470 - val_accuracy: 0.7727\n",
      "Epoch 206/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9104 - val_loss: 0.5664 - val_accuracy: 0.7922\n",
      "Epoch 207/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9430 - val_loss: 0.6253 - val_accuracy: 0.8442\n",
      "Epoch 208/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9463 - val_loss: 0.5167 - val_accuracy: 0.8442\n",
      "Epoch 209/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9609 - val_loss: 0.5344 - val_accuracy: 0.8701\n",
      "Epoch 210/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9560 - val_loss: 0.4946 - val_accuracy: 0.8571\n",
      "Epoch 211/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9625 - val_loss: 0.4843 - val_accuracy: 0.8377\n",
      "Epoch 212/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9609 - val_loss: 0.4865 - val_accuracy: 0.8571\n",
      "Epoch 213/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9593 - val_loss: 0.3665 - val_accuracy: 0.9026\n",
      "Epoch 214/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9609 - val_loss: 0.4084 - val_accuracy: 0.8636\n",
      "Epoch 215/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9577 - val_loss: 0.4727 - val_accuracy: 0.8506\n",
      "Epoch 216/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9511 - val_loss: 0.4037 - val_accuracy: 0.8766\n",
      "Epoch 217/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9479 - val_loss: 0.4532 - val_accuracy: 0.8442\n",
      "Epoch 218/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9446 - val_loss: 0.4584 - val_accuracy: 0.8182\n",
      "Epoch 219/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9528 - val_loss: 0.4605 - val_accuracy: 0.8377\n",
      "Epoch 220/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9446 - val_loss: 0.6942 - val_accuracy: 0.7987\n",
      "Epoch 221/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.9055 - val_loss: 0.4836 - val_accuracy: 0.8571\n",
      "Epoch 222/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8485 - val_loss: 0.7287 - val_accuracy: 0.7922\n",
      "Epoch 223/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.8404 - val_loss: 0.6900 - val_accuracy: 0.7987\n",
      "Epoch 224/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9039 - val_loss: 0.3934 - val_accuracy: 0.8571\n",
      "Epoch 225/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9169 - val_loss: 0.4959 - val_accuracy: 0.7597\n",
      "Epoch 226/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9235 - val_loss: 0.4135 - val_accuracy: 0.8701\n",
      "Epoch 227/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9560 - val_loss: 0.5696 - val_accuracy: 0.8442\n",
      "Epoch 228/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9479 - val_loss: 0.4608 - val_accuracy: 0.8571\n",
      "Epoch 229/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9332 - val_loss: 0.4590 - val_accuracy: 0.8506\n",
      "Epoch 230/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9528 - val_loss: 0.4374 - val_accuracy: 0.8506\n",
      "Epoch 231/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9495 - val_loss: 0.6533 - val_accuracy: 0.8182\n",
      "Epoch 232/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9544 - val_loss: 0.4232 - val_accuracy: 0.8312\n",
      "Epoch 233/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9528 - val_loss: 0.4015 - val_accuracy: 0.8506\n",
      "Epoch 234/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9463 - val_loss: 0.6299 - val_accuracy: 0.8442\n",
      "Epoch 235/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9479 - val_loss: 0.4004 - val_accuracy: 0.8506\n",
      "Epoch 236/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9446 - val_loss: 0.4642 - val_accuracy: 0.8766\n",
      "Epoch 237/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9658 - val_loss: 0.4595 - val_accuracy: 0.8442\n",
      "Epoch 238/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9511 - val_loss: 0.4717 - val_accuracy: 0.8377\n",
      "Epoch 239/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9577 - val_loss: 0.5256 - val_accuracy: 0.8377\n",
      "Epoch 240/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9528 - val_loss: 0.3944 - val_accuracy: 0.8377\n",
      "Epoch 241/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9593 - val_loss: 0.5237 - val_accuracy: 0.8506\n",
      "Epoch 242/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9609 - val_loss: 0.4381 - val_accuracy: 0.8506\n",
      "Epoch 243/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9495 - val_loss: 0.4379 - val_accuracy: 0.8571\n",
      "Epoch 244/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9560 - val_loss: 0.4146 - val_accuracy: 0.8506\n",
      "Epoch 245/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9560 - val_loss: 0.4280 - val_accuracy: 0.8442\n",
      "Epoch 246/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9625 - val_loss: 0.4440 - val_accuracy: 0.8571\n",
      "Epoch 247/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9186 - val_loss: 0.6478 - val_accuracy: 0.7792\n",
      "Epoch 248/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.9251 - val_loss: 0.6189 - val_accuracy: 0.8052\n",
      "Epoch 249/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8664 - val_loss: 0.6881 - val_accuracy: 0.8117\n",
      "Epoch 250/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.8990 - val_loss: 0.4134 - val_accuracy: 0.8442\n",
      "Epoch 251/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9300 - val_loss: 0.4612 - val_accuracy: 0.8831\n",
      "Epoch 252/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9414 - val_loss: 0.4294 - val_accuracy: 0.8636\n",
      "Epoch 253/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9349 - val_loss: 0.4403 - val_accuracy: 0.8442\n",
      "Epoch 254/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9316 - val_loss: 0.4826 - val_accuracy: 0.8377\n",
      "Epoch 255/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9397 - val_loss: 0.4276 - val_accuracy: 0.8636\n",
      "Epoch 256/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9642 - val_loss: 0.4347 - val_accuracy: 0.8442\n",
      "Epoch 257/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9593 - val_loss: 0.4927 - val_accuracy: 0.8442\n",
      "Epoch 258/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9609 - val_loss: 0.3991 - val_accuracy: 0.8636\n",
      "Epoch 259/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9430 - val_loss: 0.4107 - val_accuracy: 0.8571\n",
      "Epoch 260/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9463 - val_loss: 0.3857 - val_accuracy: 0.8831\n",
      "Epoch 261/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9055 - val_loss: 0.5396 - val_accuracy: 0.8052\n",
      "Epoch 262/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9104 - val_loss: 0.6346 - val_accuracy: 0.8182\n",
      "Epoch 263/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9381 - val_loss: 0.4349 - val_accuracy: 0.8506\n",
      "Epoch 264/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9544 - val_loss: 0.4684 - val_accuracy: 0.8117\n",
      "Epoch 265/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9593 - val_loss: 0.4640 - val_accuracy: 0.8442\n",
      "Epoch 266/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9577 - val_loss: 0.4907 - val_accuracy: 0.8442\n",
      "Epoch 267/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0995 - accuracy: 0.9593 - val_loss: 0.5663 - val_accuracy: 0.8377\n",
      "Epoch 268/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9658 - val_loss: 0.6781 - val_accuracy: 0.8312\n",
      "Epoch 269/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9446 - val_loss: 0.4790 - val_accuracy: 0.8571\n",
      "Epoch 270/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9169 - val_loss: 0.7993 - val_accuracy: 0.7857\n",
      "Epoch 271/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.9283 - val_loss: 0.5082 - val_accuracy: 0.8182\n",
      "Epoch 272/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9349 - val_loss: 0.6053 - val_accuracy: 0.8377\n",
      "Epoch 273/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9593 - val_loss: 0.3830 - val_accuracy: 0.8636\n",
      "Epoch 274/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9593 - val_loss: 0.3764 - val_accuracy: 0.8766\n",
      "Epoch 275/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9577 - val_loss: 0.4882 - val_accuracy: 0.8247\n",
      "Epoch 276/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9577 - val_loss: 0.4391 - val_accuracy: 0.8571\n",
      "Epoch 277/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9625 - val_loss: 0.4359 - val_accuracy: 0.8312\n",
      "Epoch 278/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9609 - val_loss: 0.5786 - val_accuracy: 0.8377\n",
      "Epoch 279/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9544 - val_loss: 0.5134 - val_accuracy: 0.8571\n",
      "Epoch 280/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9446 - val_loss: 0.4730 - val_accuracy: 0.8377\n",
      "Epoch 281/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9609 - val_loss: 0.4297 - val_accuracy: 0.8636\n",
      "Epoch 282/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9544 - val_loss: 0.6510 - val_accuracy: 0.8442\n",
      "Epoch 283/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9511 - val_loss: 0.5286 - val_accuracy: 0.8117\n",
      "Epoch 284/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9495 - val_loss: 0.4925 - val_accuracy: 0.8312\n",
      "Epoch 285/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9463 - val_loss: 0.4718 - val_accuracy: 0.8442\n",
      "Epoch 286/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9479 - val_loss: 0.5607 - val_accuracy: 0.8442\n",
      "Epoch 287/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9495 - val_loss: 0.5061 - val_accuracy: 0.8442\n",
      "Epoch 288/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9463 - val_loss: 0.5538 - val_accuracy: 0.8506\n",
      "Epoch 289/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9593 - val_loss: 0.5383 - val_accuracy: 0.8571\n",
      "Epoch 290/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9560 - val_loss: 0.5917 - val_accuracy: 0.8571\n",
      "Epoch 291/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9381 - val_loss: 0.4847 - val_accuracy: 0.8442\n",
      "Epoch 292/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9153 - val_loss: 0.7032 - val_accuracy: 0.8182\n",
      "Epoch 293/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8681 - val_loss: 0.6617 - val_accuracy: 0.7987\n",
      "Epoch 294/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9023 - val_loss: 0.5442 - val_accuracy: 0.8571\n",
      "Epoch 295/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9397 - val_loss: 0.5762 - val_accuracy: 0.8182\n",
      "Epoch 296/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9349 - val_loss: 0.5564 - val_accuracy: 0.8247\n",
      "Epoch 297/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9446 - val_loss: 0.4334 - val_accuracy: 0.8636\n",
      "Epoch 298/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9577 - val_loss: 0.4784 - val_accuracy: 0.8701\n",
      "Epoch 299/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9577 - val_loss: 0.4935 - val_accuracy: 0.8377\n",
      "Epoch 300/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9463 - val_loss: 0.4035 - val_accuracy: 0.8571\n",
      "Epoch 301/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9560 - val_loss: 0.5492 - val_accuracy: 0.8312\n",
      "Epoch 302/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9528 - val_loss: 0.4346 - val_accuracy: 0.8182\n",
      "Epoch 303/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9528 - val_loss: 0.4456 - val_accuracy: 0.8506\n",
      "Epoch 304/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9593 - val_loss: 0.4710 - val_accuracy: 0.8442\n",
      "Epoch 305/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9593 - val_loss: 0.5120 - val_accuracy: 0.8377\n",
      "Epoch 306/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9625 - val_loss: 0.5274 - val_accuracy: 0.8312\n",
      "Epoch 307/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9544 - val_loss: 0.4722 - val_accuracy: 0.8442\n",
      "Epoch 308/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9544 - val_loss: 0.4806 - val_accuracy: 0.8442\n",
      "Epoch 309/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9463 - val_loss: 0.4959 - val_accuracy: 0.8571\n",
      "Epoch 310/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9593 - val_loss: 0.4516 - val_accuracy: 0.8636\n",
      "Epoch 311/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9479 - val_loss: 0.4660 - val_accuracy: 0.8636\n",
      "Epoch 312/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9609 - val_loss: 0.5549 - val_accuracy: 0.8312\n",
      "Epoch 313/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9593 - val_loss: 0.4953 - val_accuracy: 0.8506\n",
      "Epoch 314/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9446 - val_loss: 0.6041 - val_accuracy: 0.8052\n",
      "Epoch 315/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9072 - val_loss: 0.7855 - val_accuracy: 0.7792\n",
      "Epoch 316/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8974 - val_loss: 0.7938 - val_accuracy: 0.8117\n",
      "Epoch 317/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8648 - val_loss: 0.4592 - val_accuracy: 0.8312\n",
      "Epoch 318/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.8111 - val_loss: 0.7618 - val_accuracy: 0.7792\n",
      "Epoch 319/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8502 - val_loss: 0.8914 - val_accuracy: 0.7857\n",
      "Epoch 320/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8990 - val_loss: 0.6651 - val_accuracy: 0.8052\n",
      "Epoch 321/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9267 - val_loss: 0.5806 - val_accuracy: 0.8182\n",
      "Epoch 322/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9153 - val_loss: 0.6853 - val_accuracy: 0.8312\n",
      "Epoch 323/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9072 - val_loss: 0.6814 - val_accuracy: 0.7987\n",
      "Epoch 324/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9414 - val_loss: 0.5983 - val_accuracy: 0.8506\n",
      "Epoch 325/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9495 - val_loss: 0.5733 - val_accuracy: 0.8312\n",
      "Epoch 326/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9577 - val_loss: 0.5819 - val_accuracy: 0.8312\n",
      "Epoch 327/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9642 - val_loss: 0.6115 - val_accuracy: 0.8117\n",
      "Epoch 328/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9577 - val_loss: 0.7124 - val_accuracy: 0.8247\n",
      "Epoch 329/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9691 - val_loss: 0.6275 - val_accuracy: 0.8312\n",
      "Epoch 330/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9560 - val_loss: 0.6633 - val_accuracy: 0.8247\n",
      "Epoch 331/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9544 - val_loss: 0.6523 - val_accuracy: 0.8312\n",
      "Epoch 332/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9658 - val_loss: 0.6625 - val_accuracy: 0.8052\n",
      "Epoch 333/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9609 - val_loss: 0.6264 - val_accuracy: 0.8506\n",
      "Epoch 334/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9609 - val_loss: 0.5472 - val_accuracy: 0.8377\n",
      "Epoch 335/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9625 - val_loss: 0.6293 - val_accuracy: 0.8442\n",
      "Epoch 336/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9609 - val_loss: 0.6455 - val_accuracy: 0.8182\n",
      "Epoch 337/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9674 - val_loss: 0.6321 - val_accuracy: 0.8377\n",
      "Epoch 338/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9511 - val_loss: 0.7539 - val_accuracy: 0.8312\n",
      "Epoch 339/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9593 - val_loss: 0.7005 - val_accuracy: 0.7987\n",
      "Epoch 340/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9544 - val_loss: 0.7126 - val_accuracy: 0.8052\n",
      "Epoch 341/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9544 - val_loss: 0.5778 - val_accuracy: 0.8571\n",
      "Epoch 342/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9544 - val_loss: 0.5698 - val_accuracy: 0.8182\n",
      "Epoch 343/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9511 - val_loss: 0.7162 - val_accuracy: 0.8117\n",
      "Epoch 344/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9560 - val_loss: 0.6110 - val_accuracy: 0.8506\n",
      "Epoch 345/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9463 - val_loss: 0.7345 - val_accuracy: 0.7987\n",
      "Epoch 346/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9153 - val_loss: 0.5696 - val_accuracy: 0.8312\n",
      "Epoch 347/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9430 - val_loss: 0.5448 - val_accuracy: 0.8247\n",
      "Epoch 348/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9251 - val_loss: 0.6771 - val_accuracy: 0.8052\n",
      "Epoch 349/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9169 - val_loss: 0.6462 - val_accuracy: 0.8377\n",
      "Epoch 350/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.9007 - val_loss: 0.5909 - val_accuracy: 0.8312\n",
      "Epoch 351/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9235 - val_loss: 0.4906 - val_accuracy: 0.8442\n",
      "Epoch 352/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9479 - val_loss: 0.5954 - val_accuracy: 0.8247\n",
      "Epoch 353/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9577 - val_loss: 0.6001 - val_accuracy: 0.8312\n",
      "Epoch 354/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9544 - val_loss: 0.6151 - val_accuracy: 0.8052\n",
      "Epoch 355/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9511 - val_loss: 0.9135 - val_accuracy: 0.8052\n",
      "Epoch 356/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9463 - val_loss: 0.5503 - val_accuracy: 0.8247\n",
      "Epoch 357/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9642 - val_loss: 0.4987 - val_accuracy: 0.8377\n",
      "Epoch 358/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9577 - val_loss: 0.4482 - val_accuracy: 0.8701\n",
      "Epoch 359/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9577 - val_loss: 0.5160 - val_accuracy: 0.8636\n",
      "Epoch 360/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9691 - val_loss: 0.5267 - val_accuracy: 0.8312\n",
      "Epoch 361/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9544 - val_loss: 0.7090 - val_accuracy: 0.8117\n",
      "Epoch 362/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9495 - val_loss: 0.4150 - val_accuracy: 0.8506\n",
      "Epoch 363/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9609 - val_loss: 0.5012 - val_accuracy: 0.8377\n",
      "Epoch 364/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9593 - val_loss: 0.5532 - val_accuracy: 0.7987\n",
      "Epoch 365/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9609 - val_loss: 0.4992 - val_accuracy: 0.8571\n",
      "Epoch 366/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9609 - val_loss: 0.4650 - val_accuracy: 0.8571\n",
      "Epoch 367/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9691 - val_loss: 0.5347 - val_accuracy: 0.8442\n",
      "Epoch 368/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9577 - val_loss: 0.5025 - val_accuracy: 0.8636\n",
      "Epoch 369/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9642 - val_loss: 0.6660 - val_accuracy: 0.8247\n",
      "Epoch 370/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9528 - val_loss: 0.6291 - val_accuracy: 0.8377\n",
      "Epoch 371/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9609 - val_loss: 0.7161 - val_accuracy: 0.7922\n",
      "Epoch 372/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9609 - val_loss: 0.6502 - val_accuracy: 0.8117\n",
      "Epoch 373/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9658 - val_loss: 0.7312 - val_accuracy: 0.8052\n",
      "Epoch 374/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9723 - val_loss: 0.5535 - val_accuracy: 0.8052\n",
      "Epoch 375/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9609 - val_loss: 0.5236 - val_accuracy: 0.8312\n",
      "Epoch 376/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9479 - val_loss: 0.5483 - val_accuracy: 0.8506\n",
      "Epoch 377/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9658 - val_loss: 0.6157 - val_accuracy: 0.8377\n",
      "Epoch 378/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9495 - val_loss: 0.7453 - val_accuracy: 0.7922\n",
      "Epoch 379/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.8567 - val_loss: 1.2140 - val_accuracy: 0.7403\n",
      "Epoch 380/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.8192 - val_loss: 0.9184 - val_accuracy: 0.7532\n",
      "Epoch 381/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8730 - val_loss: 0.6143 - val_accuracy: 0.7922\n",
      "Epoch 382/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9153 - val_loss: 0.4773 - val_accuracy: 0.8377\n",
      "Epoch 383/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9430 - val_loss: 0.5302 - val_accuracy: 0.8377\n",
      "Epoch 384/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9593 - val_loss: 0.4869 - val_accuracy: 0.8506\n",
      "Epoch 385/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9511 - val_loss: 0.4789 - val_accuracy: 0.8571\n",
      "Epoch 386/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9593 - val_loss: 0.5303 - val_accuracy: 0.8377\n",
      "Epoch 387/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9609 - val_loss: 0.5958 - val_accuracy: 0.8247\n",
      "Epoch 388/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9609 - val_loss: 0.4443 - val_accuracy: 0.8442\n",
      "Epoch 389/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9593 - val_loss: 0.5329 - val_accuracy: 0.8312\n",
      "Epoch 390/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9593 - val_loss: 0.5411 - val_accuracy: 0.8377\n",
      "Epoch 391/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9658 - val_loss: 0.5927 - val_accuracy: 0.8182\n",
      "Epoch 392/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9625 - val_loss: 0.4345 - val_accuracy: 0.8636\n",
      "Epoch 393/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9577 - val_loss: 0.6340 - val_accuracy: 0.7922\n",
      "Epoch 394/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9414 - val_loss: 0.4744 - val_accuracy: 0.8571\n",
      "Epoch 395/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9495 - val_loss: 0.6575 - val_accuracy: 0.7987\n",
      "Epoch 396/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9430 - val_loss: 0.4507 - val_accuracy: 0.8571\n",
      "Epoch 397/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9381 - val_loss: 0.6209 - val_accuracy: 0.7857\n",
      "Epoch 398/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.9039 - val_loss: 0.7840 - val_accuracy: 0.8312\n",
      "Epoch 399/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9479 - val_loss: 0.6549 - val_accuracy: 0.7857\n",
      "Epoch 400/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9316 - val_loss: 0.7446 - val_accuracy: 0.8052\n",
      "Epoch 401/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9495 - val_loss: 0.5001 - val_accuracy: 0.8312\n",
      "Epoch 402/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9658 - val_loss: 0.6233 - val_accuracy: 0.8506\n",
      "Epoch 403/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9593 - val_loss: 0.5434 - val_accuracy: 0.7987\n",
      "Epoch 404/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9691 - val_loss: 0.5844 - val_accuracy: 0.8377\n",
      "Epoch 405/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9691 - val_loss: 0.5455 - val_accuracy: 0.8247\n",
      "Epoch 406/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9544 - val_loss: 0.5825 - val_accuracy: 0.8377\n",
      "Epoch 407/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9674 - val_loss: 0.6740 - val_accuracy: 0.8377\n",
      "Epoch 408/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9577 - val_loss: 0.5459 - val_accuracy: 0.8377\n",
      "Epoch 409/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9544 - val_loss: 0.6045 - val_accuracy: 0.8442\n",
      "Epoch 410/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9674 - val_loss: 0.6403 - val_accuracy: 0.8117\n",
      "Epoch 411/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9479 - val_loss: 0.5087 - val_accuracy: 0.7987\n",
      "Epoch 412/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9479 - val_loss: 0.4629 - val_accuracy: 0.8312\n",
      "Epoch 413/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9560 - val_loss: 0.5387 - val_accuracy: 0.7857\n",
      "Epoch 414/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9609 - val_loss: 0.5310 - val_accuracy: 0.8052\n",
      "Epoch 415/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9283 - val_loss: 0.4952 - val_accuracy: 0.8571\n",
      "Epoch 416/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9349 - val_loss: 0.4758 - val_accuracy: 0.8312\n",
      "Epoch 417/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.9088 - val_loss: 0.8607 - val_accuracy: 0.7208\n",
      "Epoch 418/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8502 - val_loss: 1.0122 - val_accuracy: 0.7338\n",
      "Epoch 419/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.8779 - val_loss: 0.7590 - val_accuracy: 0.7273\n",
      "Epoch 420/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9169 - val_loss: 0.6764 - val_accuracy: 0.8117\n",
      "Epoch 421/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9072 - val_loss: 0.6318 - val_accuracy: 0.7857\n",
      "Epoch 422/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9365 - val_loss: 0.5893 - val_accuracy: 0.8052\n",
      "Epoch 423/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9397 - val_loss: 0.6319 - val_accuracy: 0.7857\n",
      "Epoch 424/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9625 - val_loss: 0.7251 - val_accuracy: 0.7792\n",
      "Epoch 425/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9625 - val_loss: 0.6259 - val_accuracy: 0.7987\n",
      "Epoch 426/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9642 - val_loss: 0.6386 - val_accuracy: 0.7662\n",
      "Epoch 427/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9691 - val_loss: 0.6418 - val_accuracy: 0.7987\n",
      "Epoch 428/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9609 - val_loss: 0.6011 - val_accuracy: 0.8052\n",
      "Epoch 429/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9463 - val_loss: 0.5929 - val_accuracy: 0.8312\n",
      "Epoch 430/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9642 - val_loss: 0.6482 - val_accuracy: 0.7857\n",
      "Epoch 431/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9625 - val_loss: 0.6680 - val_accuracy: 0.8247\n",
      "Epoch 432/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9625 - val_loss: 0.5984 - val_accuracy: 0.8052\n",
      "Epoch 433/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9707 - val_loss: 0.5578 - val_accuracy: 0.8312\n",
      "Epoch 434/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9642 - val_loss: 0.4949 - val_accuracy: 0.8506\n",
      "Epoch 435/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9609 - val_loss: 0.5595 - val_accuracy: 0.8247\n",
      "Epoch 436/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9609 - val_loss: 0.5765 - val_accuracy: 0.8571\n",
      "Epoch 437/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9577 - val_loss: 0.5028 - val_accuracy: 0.8377\n",
      "Epoch 438/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9707 - val_loss: 0.6721 - val_accuracy: 0.8052\n",
      "Epoch 439/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9642 - val_loss: 0.5326 - val_accuracy: 0.8571\n",
      "Epoch 440/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9805 - val_loss: 0.5901 - val_accuracy: 0.7727\n",
      "Epoch 441/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9691 - val_loss: 0.5461 - val_accuracy: 0.8117\n",
      "Epoch 442/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9674 - val_loss: 0.4862 - val_accuracy: 0.8312\n",
      "Epoch 443/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9691 - val_loss: 0.5174 - val_accuracy: 0.8442\n",
      "Epoch 444/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9495 - val_loss: 0.6910 - val_accuracy: 0.8052\n",
      "Epoch 445/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9528 - val_loss: 0.6259 - val_accuracy: 0.7857\n",
      "Epoch 446/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9414 - val_loss: 0.5929 - val_accuracy: 0.8117\n",
      "Epoch 447/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9609 - val_loss: 0.5449 - val_accuracy: 0.8117\n",
      "Epoch 448/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9593 - val_loss: 0.6370 - val_accuracy: 0.8247\n",
      "Epoch 449/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9479 - val_loss: 0.7989 - val_accuracy: 0.7922\n",
      "Epoch 450/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9251 - val_loss: 0.6197 - val_accuracy: 0.8701\n",
      "Epoch 451/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9463 - val_loss: 0.5275 - val_accuracy: 0.8377\n",
      "Epoch 452/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9283 - val_loss: 0.5263 - val_accuracy: 0.8701\n",
      "Epoch 453/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.9202 - val_loss: 0.8854 - val_accuracy: 0.7922\n",
      "Epoch 454/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9414 - val_loss: 0.5786 - val_accuracy: 0.7987\n",
      "Epoch 455/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9316 - val_loss: 0.6386 - val_accuracy: 0.8312\n",
      "Epoch 456/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9463 - val_loss: 0.5354 - val_accuracy: 0.8636\n",
      "Epoch 457/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9609 - val_loss: 0.4756 - val_accuracy: 0.8312\n",
      "Epoch 458/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9674 - val_loss: 0.5099 - val_accuracy: 0.8312\n",
      "Epoch 459/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9528 - val_loss: 0.6570 - val_accuracy: 0.8247\n",
      "Epoch 460/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9137 - val_loss: 0.6064 - val_accuracy: 0.7987\n",
      "Epoch 461/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9544 - val_loss: 0.4880 - val_accuracy: 0.8117\n",
      "Epoch 462/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9479 - val_loss: 0.6159 - val_accuracy: 0.8117\n",
      "Epoch 463/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9642 - val_loss: 0.5922 - val_accuracy: 0.8052\n",
      "Epoch 464/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9495 - val_loss: 0.4757 - val_accuracy: 0.8636\n",
      "Epoch 465/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9544 - val_loss: 0.4926 - val_accuracy: 0.8312\n",
      "Epoch 466/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9528 - val_loss: 0.5020 - val_accuracy: 0.8571\n",
      "Epoch 467/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9609 - val_loss: 0.5834 - val_accuracy: 0.8312\n",
      "Epoch 468/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9511 - val_loss: 0.5939 - val_accuracy: 0.8182\n",
      "Epoch 469/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9625 - val_loss: 0.5546 - val_accuracy: 0.8312\n",
      "Epoch 470/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9544 - val_loss: 0.5289 - val_accuracy: 0.8182\n",
      "Epoch 471/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9397 - val_loss: 0.7626 - val_accuracy: 0.7792\n",
      "Epoch 472/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8974 - val_loss: 0.5827 - val_accuracy: 0.7987\n",
      "Epoch 473/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9251 - val_loss: 0.6291 - val_accuracy: 0.7987\n",
      "Epoch 474/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9365 - val_loss: 0.5880 - val_accuracy: 0.8182\n",
      "Epoch 475/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9495 - val_loss: 0.5107 - val_accuracy: 0.8182\n",
      "Epoch 476/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9430 - val_loss: 0.4789 - val_accuracy: 0.8442\n",
      "Epoch 477/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9625 - val_loss: 0.5235 - val_accuracy: 0.8247\n",
      "Epoch 478/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9625 - val_loss: 0.7329 - val_accuracy: 0.7987\n",
      "Epoch 479/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9560 - val_loss: 0.4506 - val_accuracy: 0.8117\n",
      "Epoch 480/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9609 - val_loss: 0.4401 - val_accuracy: 0.8571\n",
      "Epoch 481/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9593 - val_loss: 0.4815 - val_accuracy: 0.8377\n",
      "Epoch 482/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9707 - val_loss: 0.5507 - val_accuracy: 0.8312\n",
      "Epoch 483/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9691 - val_loss: 0.5702 - val_accuracy: 0.8312\n",
      "Epoch 484/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9674 - val_loss: 0.5869 - val_accuracy: 0.8117\n",
      "Epoch 485/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9577 - val_loss: 0.5871 - val_accuracy: 0.8052\n",
      "Epoch 486/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9430 - val_loss: 0.9182 - val_accuracy: 0.7922\n",
      "Epoch 487/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9072 - val_loss: 0.6331 - val_accuracy: 0.7987\n",
      "Epoch 488/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8730 - val_loss: 0.6458 - val_accuracy: 0.7857\n",
      "Epoch 489/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8779 - val_loss: 0.5968 - val_accuracy: 0.7922\n",
      "Epoch 490/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9283 - val_loss: 0.5561 - val_accuracy: 0.8247\n",
      "Epoch 491/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9414 - val_loss: 0.5008 - val_accuracy: 0.7857\n",
      "Epoch 492/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9707 - val_loss: 0.4660 - val_accuracy: 0.8182\n",
      "Epoch 493/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9691 - val_loss: 0.5643 - val_accuracy: 0.8052\n",
      "Epoch 494/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9642 - val_loss: 0.4262 - val_accuracy: 0.8312\n",
      "Epoch 495/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9707 - val_loss: 0.6694 - val_accuracy: 0.8052\n",
      "Epoch 496/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9609 - val_loss: 0.4146 - val_accuracy: 0.8247\n",
      "Epoch 497/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9707 - val_loss: 0.5476 - val_accuracy: 0.8247\n",
      "Epoch 498/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9723 - val_loss: 0.5573 - val_accuracy: 0.8312\n",
      "Epoch 499/500\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9691 - val_loss: 0.5200 - val_accuracy: 0.8052\n",
      "Epoch 500/500\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9691 - val_loss: 0.5565 - val_accuracy: 0.8377\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y, epochs=500,validation_split=0.20, batch_size=10, verbose=1) #Accuracy 90 with epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd188016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f3fe80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f123f778e0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"ValAccuracy\")\n",
    "plt.legend()\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f484d0",
   "metadata": {},
   "source": [
    "2-Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d476111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3221f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('kc_house.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2947ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"kc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "705705d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  ...  zipcode_98146  zipcode_98148  zipcode_98155  \\\n",
       "0     1.0   65          0  ...              0              0              0   \n",
       "1     2.0   69          1  ...              0              0              0   \n",
       "2     1.0   87          0  ...              0              0              0   \n",
       "3     1.0   55          0  ...              0              0              0   \n",
       "4     1.0   33          0  ...              0              0              0   \n",
       "\n",
       "   zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  zipcode_98188  \\\n",
       "0              0              0              0              1              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98198  zipcode_98199  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea903476",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.loc[:, df.columns != \"price\"]\n",
    "#x=df.drop(\"price\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b64dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e545513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d77e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57c81624",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1436e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(81,activation='relu')) #sutun sayisi ilk\n",
    "model.add(Dense(162,activation='relu'))\n",
    "model.add(Dense(324,activation='relu'))\n",
    "model.add(Dense(648,activation='relu'))\n",
    "model.add(Dense(324,activation='relu'))\n",
    "model.add(Dense(162,activation='relu'))\n",
    "model.add(Dense(81,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f5a1625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8615800832.0000 - val_loss: 10555101184.0000\n",
      "Epoch 2/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8841509888.0000 - val_loss: 8522972672.0000\n",
      "Epoch 3/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8529003520.0000 - val_loss: 8683358208.0000\n",
      "Epoch 4/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8633269248.0000 - val_loss: 10850232320.0000\n",
      "Epoch 5/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8318365696.0000 - val_loss: 9202260992.0000\n",
      "Epoch 6/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8371302912.0000 - val_loss: 8962380800.0000\n",
      "Epoch 7/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8470893568.0000 - val_loss: 9016803328.0000\n",
      "Epoch 8/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8965545984.0000 - val_loss: 8644051968.0000\n",
      "Epoch 9/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8893481984.0000 - val_loss: 8866850816.0000\n",
      "Epoch 10/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8702344192.0000 - val_loss: 8513316352.0000\n",
      "Epoch 11/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8309617664.0000 - val_loss: 8637948928.0000\n",
      "Epoch 12/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8264459776.0000 - val_loss: 8834398208.0000\n",
      "Epoch 13/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8240785920.0000 - val_loss: 9750278144.0000\n",
      "Epoch 14/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8681351168.0000 - val_loss: 8879518720.0000\n",
      "Epoch 15/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 9137599488.0000 - val_loss: 14687425536.0000\n",
      "Epoch 16/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8565787136.0000 - val_loss: 9004499968.0000\n",
      "Epoch 17/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8729666560.0000 - val_loss: 8625747968.0000\n",
      "Epoch 18/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8296950272.0000 - val_loss: 9169660928.0000\n",
      "Epoch 19/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 9058033664.0000 - val_loss: 8520680960.0000\n",
      "Epoch 20/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8474004480.0000 - val_loss: 8730376192.0000\n",
      "Epoch 21/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8490168832.0000 - val_loss: 8509331456.0000\n",
      "Epoch 22/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8779736064.0000 - val_loss: 8939539456.0000\n",
      "Epoch 23/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8263165952.0000 - val_loss: 9856864256.0000\n",
      "Epoch 24/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8424547840.0000 - val_loss: 8404994048.0000\n",
      "Epoch 25/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8164020736.0000 - val_loss: 8440188928.0000\n",
      "Epoch 26/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8463733760.0000 - val_loss: 8548965888.0000\n",
      "Epoch 27/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 9057967104.0000 - val_loss: 8579980800.0000\n",
      "Epoch 28/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8254367232.0000 - val_loss: 8793616384.0000\n",
      "Epoch 29/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8823320576.0000 - val_loss: 11402698752.0000\n",
      "Epoch 30/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8306916864.0000 - val_loss: 8472802816.0000\n",
      "Epoch 31/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8547907584.0000 - val_loss: 11432205312.0000\n",
      "Epoch 32/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8757896192.0000 - val_loss: 8695284736.0000\n",
      "Epoch 33/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8415665664.0000 - val_loss: 8616069120.0000\n",
      "Epoch 34/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8367959552.0000 - val_loss: 8808260608.0000\n",
      "Epoch 35/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8267824640.0000 - val_loss: 9145407488.0000\n",
      "Epoch 36/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9089449984.0000 - val_loss: 9213742080.0000\n",
      "Epoch 37/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8334156288.0000 - val_loss: 9422331904.0000\n",
      "Epoch 38/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8304134656.0000 - val_loss: 8957756416.0000\n",
      "Epoch 39/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8735129600.0000 - val_loss: 13085555712.0000\n",
      "Epoch 40/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8431035392.0000 - val_loss: 9113977856.0000\n",
      "Epoch 41/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8559592448.0000 - val_loss: 8676492288.0000\n",
      "Epoch 42/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8127793152.0000 - val_loss: 8678683648.0000\n",
      "Epoch 43/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8430778368.0000 - val_loss: 8900622336.0000\n",
      "Epoch 44/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8850740224.0000 - val_loss: 8455143936.0000\n",
      "Epoch 45/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8345027584.0000 - val_loss: 8705243136.0000\n",
      "Epoch 46/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9358799872.0000 - val_loss: 11365616640.0000\n",
      "Epoch 47/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8341211648.0000 - val_loss: 8696175616.0000\n",
      "Epoch 48/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8206897664.0000 - val_loss: 8772561920.0000\n",
      "Epoch 49/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8335825408.0000 - val_loss: 9079811072.0000\n",
      "Epoch 50/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8073595904.0000 - val_loss: 8490293760.0000\n",
      "Epoch 51/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8167541760.0000 - val_loss: 10931429376.0000\n",
      "Epoch 52/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8173496320.0000 - val_loss: 8559886848.0000\n",
      "Epoch 53/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8654263296.0000 - val_loss: 9269791744.0000\n",
      "Epoch 54/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8949117952.0000 - val_loss: 9024953344.0000\n",
      "Epoch 55/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8256704512.0000 - val_loss: 11687965696.0000\n",
      "Epoch 56/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8837305344.0000 - val_loss: 9512469504.0000\n",
      "Epoch 57/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8531888128.0000 - val_loss: 8682394624.0000\n",
      "Epoch 58/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8347457024.0000 - val_loss: 9208768512.0000\n",
      "Epoch 59/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8236542976.0000 - val_loss: 8490128384.0000\n",
      "Epoch 60/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8411695104.0000 - val_loss: 8488757248.0000\n",
      "Epoch 61/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8262930944.0000 - val_loss: 8391661568.0000\n",
      "Epoch 62/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8387240448.0000 - val_loss: 8502061568.0000\n",
      "Epoch 63/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8299877376.0000 - val_loss: 9008155648.0000\n",
      "Epoch 64/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7953192960.0000 - val_loss: 8589555200.0000\n",
      "Epoch 65/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8665417728.0000 - val_loss: 11309175808.0000\n",
      "Epoch 66/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8384183296.0000 - val_loss: 8678358016.0000\n",
      "Epoch 67/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8478368768.0000 - val_loss: 8498292736.0000\n",
      "Epoch 68/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8449047040.0000 - val_loss: 8289529344.0000\n",
      "Epoch 69/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7995804672.0000 - val_loss: 8585389056.0000\n",
      "Epoch 70/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8394085888.0000 - val_loss: 8363644416.0000\n",
      "Epoch 71/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8095553024.0000 - val_loss: 9187843072.0000\n",
      "Epoch 72/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8298159616.0000 - val_loss: 9248256000.0000\n",
      "Epoch 73/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8751694848.0000 - val_loss: 8451521024.0000\n",
      "Epoch 74/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8273556992.0000 - val_loss: 9126205440.0000\n",
      "Epoch 75/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8216331264.0000 - val_loss: 8444017664.0000\n",
      "Epoch 76/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8650599424.0000 - val_loss: 8794786816.0000\n",
      "Epoch 77/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7984155648.0000 - val_loss: 8949853184.0000\n",
      "Epoch 78/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8126331392.0000 - val_loss: 8435418112.0000\n",
      "Epoch 79/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8144072192.0000 - val_loss: 8679463936.0000\n",
      "Epoch 80/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8674709504.0000 - val_loss: 8679834624.0000\n",
      "Epoch 81/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8395248640.0000 - val_loss: 9417296896.0000\n",
      "Epoch 82/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8049497600.0000 - val_loss: 9633892352.0000\n",
      "Epoch 83/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7961189888.0000 - val_loss: 8691657728.0000\n",
      "Epoch 84/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8182133760.0000 - val_loss: 8785058816.0000\n",
      "Epoch 85/800\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 8031842816.0000 - val_loss: 8305220608.0000\n",
      "Epoch 86/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8589095936.0000 - val_loss: 8996705280.0000\n",
      "Epoch 87/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8530087936.0000 - val_loss: 9130151936.0000\n",
      "Epoch 88/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8887511040.0000 - val_loss: 9064912896.0000\n",
      "Epoch 89/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 9578955776.0000 - val_loss: 8640276480.0000\n",
      "Epoch 90/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7865005056.0000 - val_loss: 8324162560.0000\n",
      "Epoch 91/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8103555072.0000 - val_loss: 8571384320.0000\n",
      "Epoch 92/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8260308480.0000 - val_loss: 8550529024.0000\n",
      "Epoch 93/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8525190656.0000 - val_loss: 8506092544.0000\n",
      "Epoch 94/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8019905536.0000 - val_loss: 8321460736.0000\n",
      "Epoch 95/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8477394432.0000 - val_loss: 10208513024.0000\n",
      "Epoch 96/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8307218432.0000 - val_loss: 10761886720.0000\n",
      "Epoch 97/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8238696448.0000 - val_loss: 8719675392.0000\n",
      "Epoch 98/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8924547072.0000 - val_loss: 8355598336.0000\n",
      "Epoch 99/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8139311104.0000 - val_loss: 8571437056.0000\n",
      "Epoch 100/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8070222336.0000 - val_loss: 8579698688.0000\n",
      "Epoch 101/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8101071872.0000 - val_loss: 8592193536.0000\n",
      "Epoch 102/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8218781696.0000 - val_loss: 8356467200.0000\n",
      "Epoch 103/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8356789760.0000 - val_loss: 8840144896.0000\n",
      "Epoch 104/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8200488960.0000 - val_loss: 8512033280.0000\n",
      "Epoch 105/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8534898176.0000 - val_loss: 8307698176.0000\n",
      "Epoch 106/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8222593536.0000 - val_loss: 8477332480.0000\n",
      "Epoch 107/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8221418496.0000 - val_loss: 9276869632.0000\n",
      "Epoch 108/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7993058304.0000 - val_loss: 8352719360.0000\n",
      "Epoch 109/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7912125952.0000 - val_loss: 9033178112.0000\n",
      "Epoch 110/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7961265152.0000 - val_loss: 8525472256.0000\n",
      "Epoch 111/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8158884864.0000 - val_loss: 10276310016.0000\n",
      "Epoch 112/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7875909632.0000 - val_loss: 8488624128.0000\n",
      "Epoch 113/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8243415040.0000 - val_loss: 8729526272.0000\n",
      "Epoch 114/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8246655488.0000 - val_loss: 9611779072.0000\n",
      "Epoch 115/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8268406784.0000 - val_loss: 8718562304.0000\n",
      "Epoch 116/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8104974336.0000 - val_loss: 8546023424.0000\n",
      "Epoch 117/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8091753472.0000 - val_loss: 11151755264.0000\n",
      "Epoch 118/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7940653568.0000 - val_loss: 8280614912.0000\n",
      "Epoch 119/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8147712512.0000 - val_loss: 8467325952.0000\n",
      "Epoch 120/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8221186048.0000 - val_loss: 8226123776.0000\n",
      "Epoch 121/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8191268864.0000 - val_loss: 8332473856.0000\n",
      "Epoch 122/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8234504192.0000 - val_loss: 10375072768.0000\n",
      "Epoch 123/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7791331840.0000 - val_loss: 8476818432.0000\n",
      "Epoch 124/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8126999040.0000 - val_loss: 8331100672.0000\n",
      "Epoch 125/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8000158208.0000 - val_loss: 8539020288.0000\n",
      "Epoch 126/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7929845248.0000 - val_loss: 8268104704.0000\n",
      "Epoch 127/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7939252224.0000 - val_loss: 8328154112.0000\n",
      "Epoch 128/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8366760960.0000 - val_loss: 9608655872.0000\n",
      "Epoch 129/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8226265600.0000 - val_loss: 8340262400.0000\n",
      "Epoch 130/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7951617024.0000 - val_loss: 8353634304.0000\n",
      "Epoch 131/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8115192320.0000 - val_loss: 8301276672.0000\n",
      "Epoch 132/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7890577920.0000 - val_loss: 10141778944.0000\n",
      "Epoch 133/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8119716352.0000 - val_loss: 9067686912.0000\n",
      "Epoch 134/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8516901376.0000 - val_loss: 8993998848.0000\n",
      "Epoch 135/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7923500544.0000 - val_loss: 9545566208.0000\n",
      "Epoch 136/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8493445120.0000 - val_loss: 10266959872.0000\n",
      "Epoch 137/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8340193792.0000 - val_loss: 8240218112.0000\n",
      "Epoch 138/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8405384704.0000 - val_loss: 9177648128.0000\n",
      "Epoch 139/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8080400384.0000 - val_loss: 9751632896.0000\n",
      "Epoch 140/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8189686272.0000 - val_loss: 8484749312.0000\n",
      "Epoch 141/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7838053376.0000 - val_loss: 8403076096.0000\n",
      "Epoch 142/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8109648384.0000 - val_loss: 8633511936.0000\n",
      "Epoch 143/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8016398336.0000 - val_loss: 11118616576.0000\n",
      "Epoch 144/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8428563968.0000 - val_loss: 8474075136.0000\n",
      "Epoch 145/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7791210496.0000 - val_loss: 8822796288.0000\n",
      "Epoch 146/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8236444672.0000 - val_loss: 11749548032.0000\n",
      "Epoch 147/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7859277312.0000 - val_loss: 8718955520.0000\n",
      "Epoch 148/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7965784576.0000 - val_loss: 8426083840.0000\n",
      "Epoch 149/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8150602752.0000 - val_loss: 10535336960.0000\n",
      "Epoch 150/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7788211200.0000 - val_loss: 8391535104.0000\n",
      "Epoch 151/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7719655424.0000 - val_loss: 8959414272.0000\n",
      "Epoch 152/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8461518848.0000 - val_loss: 11792375808.0000\n",
      "Epoch 153/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8038863360.0000 - val_loss: 10551251968.0000\n",
      "Epoch 154/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7948331520.0000 - val_loss: 8402693120.0000\n",
      "Epoch 155/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7783589376.0000 - val_loss: 8347123712.0000\n",
      "Epoch 156/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7808792064.0000 - val_loss: 8263003648.0000\n",
      "Epoch 157/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8066201088.0000 - val_loss: 12430235648.0000\n",
      "Epoch 158/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8172976640.0000 - val_loss: 8422548480.0000\n",
      "Epoch 159/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8055617536.0000 - val_loss: 9254744064.0000\n",
      "Epoch 160/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7800665088.0000 - val_loss: 12239177728.0000\n",
      "Epoch 161/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8009744384.0000 - val_loss: 8974052352.0000\n",
      "Epoch 162/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7900088832.0000 - val_loss: 9428153344.0000\n",
      "Epoch 163/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7907651072.0000 - val_loss: 12840162304.0000\n",
      "Epoch 164/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8610266112.0000 - val_loss: 8484535808.0000\n",
      "Epoch 165/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7983104512.0000 - val_loss: 8230336000.0000\n",
      "Epoch 166/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7952640512.0000 - val_loss: 9653805056.0000\n",
      "Epoch 167/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7953142272.0000 - val_loss: 8199528448.0000\n",
      "Epoch 168/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7943834624.0000 - val_loss: 9633364992.0000\n",
      "Epoch 169/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7845787648.0000 - val_loss: 9915698176.0000\n",
      "Epoch 170/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7931665920.0000 - val_loss: 8438196224.0000\n",
      "Epoch 171/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7893270016.0000 - val_loss: 8668834816.0000\n",
      "Epoch 172/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8070308864.0000 - val_loss: 8495663616.0000\n",
      "Epoch 173/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8106468864.0000 - val_loss: 8249088000.0000\n",
      "Epoch 174/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7820065792.0000 - val_loss: 8210138624.0000\n",
      "Epoch 175/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7645794816.0000 - val_loss: 8654239744.0000\n",
      "Epoch 176/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7936876032.0000 - val_loss: 8411424256.0000\n",
      "Epoch 177/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7925504000.0000 - val_loss: 8331907072.0000\n",
      "Epoch 178/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7839897088.0000 - val_loss: 8406052352.0000\n",
      "Epoch 179/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7844044288.0000 - val_loss: 8515894272.0000\n",
      "Epoch 180/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7888345600.0000 - val_loss: 8911918080.0000\n",
      "Epoch 181/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7892462592.0000 - val_loss: 9066341376.0000\n",
      "Epoch 182/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8042060800.0000 - val_loss: 9340464128.0000\n",
      "Epoch 183/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7715168768.0000 - val_loss: 8550862848.0000\n",
      "Epoch 184/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7558165504.0000 - val_loss: 8288339456.0000\n",
      "Epoch 185/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8238159872.0000 - val_loss: 9349335040.0000\n",
      "Epoch 186/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7811163136.0000 - val_loss: 10143124480.0000\n",
      "Epoch 187/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8168125952.0000 - val_loss: 10444947456.0000\n",
      "Epoch 188/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7924634624.0000 - val_loss: 10287610880.0000\n",
      "Epoch 189/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8178997248.0000 - val_loss: 8379160064.0000\n",
      "Epoch 190/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7935997952.0000 - val_loss: 8388482560.0000\n",
      "Epoch 191/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7518977536.0000 - val_loss: 8710758400.0000\n",
      "Epoch 192/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8132476928.0000 - val_loss: 9546885120.0000\n",
      "Epoch 193/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7848198656.0000 - val_loss: 9271005184.0000\n",
      "Epoch 194/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7978000384.0000 - val_loss: 8325154304.0000\n",
      "Epoch 195/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7640961536.0000 - val_loss: 8539900928.0000\n",
      "Epoch 196/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8027868160.0000 - val_loss: 10962667520.0000\n",
      "Epoch 197/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7949413376.0000 - val_loss: 8567163392.0000\n",
      "Epoch 198/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7803534848.0000 - val_loss: 9454441472.0000\n",
      "Epoch 199/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7616639488.0000 - val_loss: 9956413440.0000\n",
      "Epoch 200/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7759514624.0000 - val_loss: 8267826688.0000\n",
      "Epoch 201/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8649494528.0000 - val_loss: 8206238720.0000\n",
      "Epoch 202/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7844945920.0000 - val_loss: 8463396352.0000\n",
      "Epoch 203/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7971738624.0000 - val_loss: 9184133120.0000\n",
      "Epoch 204/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8095013376.0000 - val_loss: 8512985088.0000\n",
      "Epoch 205/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7543543296.0000 - val_loss: 8365241344.0000\n",
      "Epoch 206/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7842520064.0000 - val_loss: 8464271872.0000\n",
      "Epoch 207/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7672320000.0000 - val_loss: 8434518016.0000\n",
      "Epoch 208/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7823969280.0000 - val_loss: 9500306432.0000\n",
      "Epoch 209/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8651566080.0000 - val_loss: 8703513600.0000\n",
      "Epoch 210/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7777392640.0000 - val_loss: 8758653952.0000\n",
      "Epoch 211/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7864699904.0000 - val_loss: 8656866304.0000\n",
      "Epoch 212/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7489913344.0000 - val_loss: 8323047936.0000\n",
      "Epoch 213/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7491191808.0000 - val_loss: 8918640640.0000\n",
      "Epoch 214/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8038917120.0000 - val_loss: 8360221696.0000\n",
      "Epoch 215/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7458068480.0000 - val_loss: 9090857984.0000\n",
      "Epoch 216/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7962990592.0000 - val_loss: 8371131392.0000\n",
      "Epoch 217/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7696178688.0000 - val_loss: 9352676352.0000\n",
      "Epoch 218/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7529660928.0000 - val_loss: 8221562368.0000\n",
      "Epoch 219/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7500827136.0000 - val_loss: 8518617088.0000\n",
      "Epoch 220/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7422183936.0000 - val_loss: 8906284032.0000\n",
      "Epoch 221/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8190363136.0000 - val_loss: 12513557504.0000\n",
      "Epoch 222/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7648282112.0000 - val_loss: 8723844096.0000\n",
      "Epoch 223/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7784791040.0000 - val_loss: 8536924160.0000\n",
      "Epoch 224/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7679452672.0000 - val_loss: 8109894656.0000\n",
      "Epoch 225/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7593670144.0000 - val_loss: 8250086400.0000\n",
      "Epoch 226/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 8175800832.0000 - val_loss: 13319014400.0000\n",
      "Epoch 227/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7981001216.0000 - val_loss: 8664355840.0000\n",
      "Epoch 228/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7601107968.0000 - val_loss: 8173033984.0000\n",
      "Epoch 229/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7293651456.0000 - val_loss: 8476831744.0000\n",
      "Epoch 230/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8461185024.0000 - val_loss: 8277270016.0000\n",
      "Epoch 231/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7621809152.0000 - val_loss: 8861344768.0000\n",
      "Epoch 232/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7714116096.0000 - val_loss: 8447498240.0000\n",
      "Epoch 233/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7647005696.0000 - val_loss: 9100466176.0000\n",
      "Epoch 234/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7614481920.0000 - val_loss: 9257368576.0000\n",
      "Epoch 235/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7538988544.0000 - val_loss: 8408341504.0000\n",
      "Epoch 236/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7453272064.0000 - val_loss: 9479292928.0000\n",
      "Epoch 237/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7877900800.0000 - val_loss: 8947109888.0000\n",
      "Epoch 238/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7419682304.0000 - val_loss: 8299402240.0000\n",
      "Epoch 239/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7767797760.0000 - val_loss: 8198355456.0000\n",
      "Epoch 240/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7893291008.0000 - val_loss: 9404441600.0000\n",
      "Epoch 241/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7740269056.0000 - val_loss: 8378142720.0000\n",
      "Epoch 242/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7845808640.0000 - val_loss: 8860883968.0000\n",
      "Epoch 243/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7640769024.0000 - val_loss: 8190995456.0000\n",
      "Epoch 244/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7313899008.0000 - val_loss: 8423483392.0000\n",
      "Epoch 245/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7526445568.0000 - val_loss: 8645115904.0000\n",
      "Epoch 246/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7727168000.0000 - val_loss: 8245716480.0000\n",
      "Epoch 247/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8303823872.0000 - val_loss: 8357200384.0000\n",
      "Epoch 248/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7590980608.0000 - val_loss: 11155848192.0000\n",
      "Epoch 249/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8108202496.0000 - val_loss: 9570576384.0000\n",
      "Epoch 250/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7640975872.0000 - val_loss: 8338513408.0000\n",
      "Epoch 251/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7920655360.0000 - val_loss: 8611956736.0000\n",
      "Epoch 252/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7533604864.0000 - val_loss: 8539457024.0000\n",
      "Epoch 253/800\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7377121280.0000 - val_loss: 8843168768.0000\n",
      "Epoch 254/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7473059840.0000 - val_loss: 8280212480.0000\n",
      "Epoch 255/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7582497792.0000 - val_loss: 8538804224.0000\n",
      "Epoch 256/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7348193280.0000 - val_loss: 8299321344.0000\n",
      "Epoch 257/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7887689728.0000 - val_loss: 9846515712.0000\n",
      "Epoch 258/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7737366528.0000 - val_loss: 8403832320.0000\n",
      "Epoch 259/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7634126848.0000 - val_loss: 9348317184.0000\n",
      "Epoch 260/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7281622528.0000 - val_loss: 8554829312.0000\n",
      "Epoch 261/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7464560640.0000 - val_loss: 8761902080.0000\n",
      "Epoch 262/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7382208512.0000 - val_loss: 9013523456.0000\n",
      "Epoch 263/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7734935552.0000 - val_loss: 8985357312.0000\n",
      "Epoch 264/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7256093696.0000 - val_loss: 8326149632.0000\n",
      "Epoch 265/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7441564672.0000 - val_loss: 8405981184.0000\n",
      "Epoch 266/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7428045312.0000 - val_loss: 8500685312.0000\n",
      "Epoch 267/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7694508032.0000 - val_loss: 8323035648.0000\n",
      "Epoch 268/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7795119104.0000 - val_loss: 9555885056.0000\n",
      "Epoch 269/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7830489600.0000 - val_loss: 10068471808.0000\n",
      "Epoch 270/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7508462592.0000 - val_loss: 8628337664.0000\n",
      "Epoch 271/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7797869568.0000 - val_loss: 8364421120.0000\n",
      "Epoch 272/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7325057024.0000 - val_loss: 8784784384.0000\n",
      "Epoch 273/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7319938560.0000 - val_loss: 8334590464.0000\n",
      "Epoch 274/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7220286976.0000 - val_loss: 9813341184.0000\n",
      "Epoch 275/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7748205568.0000 - val_loss: 8194100736.0000\n",
      "Epoch 276/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7223444480.0000 - val_loss: 8306084864.0000\n",
      "Epoch 277/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7539095552.0000 - val_loss: 9337506816.0000\n",
      "Epoch 278/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7741465088.0000 - val_loss: 10945661952.0000\n",
      "Epoch 279/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7685271552.0000 - val_loss: 8463138816.0000\n",
      "Epoch 280/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7458816512.0000 - val_loss: 8373465088.0000\n",
      "Epoch 281/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7461117440.0000 - val_loss: 8605882368.0000\n",
      "Epoch 282/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7452494336.0000 - val_loss: 8243136512.0000\n",
      "Epoch 283/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7842438144.0000 - val_loss: 8331713536.0000\n",
      "Epoch 284/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8024649728.0000 - val_loss: 8516243456.0000\n",
      "Epoch 285/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7357880832.0000 - val_loss: 8898595840.0000\n",
      "Epoch 286/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7312663552.0000 - val_loss: 8433447424.0000\n",
      "Epoch 287/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7716738048.0000 - val_loss: 8449565184.0000\n",
      "Epoch 288/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7357921792.0000 - val_loss: 8215676416.0000\n",
      "Epoch 289/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7701945344.0000 - val_loss: 8458037248.0000\n",
      "Epoch 290/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7407056384.0000 - val_loss: 9025634304.0000\n",
      "Epoch 291/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7375077888.0000 - val_loss: 8165579776.0000\n",
      "Epoch 292/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7619312640.0000 - val_loss: 9037377536.0000\n",
      "Epoch 293/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7891969024.0000 - val_loss: 8580573184.0000\n",
      "Epoch 294/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7280157184.0000 - val_loss: 8771793920.0000\n",
      "Epoch 295/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7671050752.0000 - val_loss: 9421847552.0000\n",
      "Epoch 296/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7771143168.0000 - val_loss: 8744342528.0000\n",
      "Epoch 297/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7629095936.0000 - val_loss: 8554701824.0000\n",
      "Epoch 298/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7362651648.0000 - val_loss: 9017664512.0000\n",
      "Epoch 299/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7422726144.0000 - val_loss: 10632775680.0000\n",
      "Epoch 300/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7670742016.0000 - val_loss: 8200082944.0000\n",
      "Epoch 301/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7574323712.0000 - val_loss: 8343528960.0000\n",
      "Epoch 302/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7417469440.0000 - val_loss: 9731068928.0000\n",
      "Epoch 303/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7467052544.0000 - val_loss: 8805214208.0000\n",
      "Epoch 304/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8069596672.0000 - val_loss: 8247290368.0000\n",
      "Epoch 305/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7206217216.0000 - val_loss: 8151450624.0000\n",
      "Epoch 306/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7322230784.0000 - val_loss: 8195966976.0000\n",
      "Epoch 307/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7461032960.0000 - val_loss: 8310309888.0000\n",
      "Epoch 308/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7117464576.0000 - val_loss: 8791592960.0000\n",
      "Epoch 309/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7567015936.0000 - val_loss: 8243979776.0000\n",
      "Epoch 310/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7400228352.0000 - val_loss: 8310299136.0000\n",
      "Epoch 311/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7339222528.0000 - val_loss: 9188298752.0000\n",
      "Epoch 312/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7301248000.0000 - val_loss: 8172954624.0000\n",
      "Epoch 313/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7735070208.0000 - val_loss: 8236285440.0000\n",
      "Epoch 314/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7223004672.0000 - val_loss: 9474442240.0000\n",
      "Epoch 315/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7399708160.0000 - val_loss: 9926839296.0000\n",
      "Epoch 316/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7326085120.0000 - val_loss: 9014907904.0000\n",
      "Epoch 317/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7359362048.0000 - val_loss: 9178648576.0000\n",
      "Epoch 318/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7553727488.0000 - val_loss: 8285019136.0000\n",
      "Epoch 319/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7250466816.0000 - val_loss: 8427309568.0000\n",
      "Epoch 320/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7487704064.0000 - val_loss: 8437252096.0000\n",
      "Epoch 321/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7700329472.0000 - val_loss: 8523361280.0000\n",
      "Epoch 322/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7679555584.0000 - val_loss: 8263150080.0000\n",
      "Epoch 323/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7374173184.0000 - val_loss: 8247822336.0000\n",
      "Epoch 324/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7328068096.0000 - val_loss: 8947339264.0000\n",
      "Epoch 325/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7223227904.0000 - val_loss: 8687154176.0000\n",
      "Epoch 326/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7443037184.0000 - val_loss: 9079494656.0000\n",
      "Epoch 327/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7147891200.0000 - val_loss: 8355197440.0000\n",
      "Epoch 328/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7306117120.0000 - val_loss: 8484834816.0000\n",
      "Epoch 329/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7001461248.0000 - val_loss: 8298819072.0000\n",
      "Epoch 330/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7181006848.0000 - val_loss: 8721203200.0000\n",
      "Epoch 331/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7558992384.0000 - val_loss: 9761654784.0000\n",
      "Epoch 332/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7279733248.0000 - val_loss: 8193451520.0000\n",
      "Epoch 333/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7226221568.0000 - val_loss: 8818831360.0000\n",
      "Epoch 334/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7147494912.0000 - val_loss: 8405540352.0000\n",
      "Epoch 335/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7155133440.0000 - val_loss: 10993581056.0000\n",
      "Epoch 336/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7654598144.0000 - val_loss: 8302808576.0000\n",
      "Epoch 337/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7375728640.0000 - val_loss: 8615769088.0000\n",
      "Epoch 338/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7396447744.0000 - val_loss: 8532695040.0000\n",
      "Epoch 339/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7551703040.0000 - val_loss: 8513069568.0000\n",
      "Epoch 340/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7285543424.0000 - val_loss: 10056822784.0000\n",
      "Epoch 341/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7431499776.0000 - val_loss: 9510924288.0000\n",
      "Epoch 342/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7440200192.0000 - val_loss: 8734300160.0000\n",
      "Epoch 343/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7162259968.0000 - val_loss: 9835985920.0000\n",
      "Epoch 344/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7064990720.0000 - val_loss: 8445145088.0000\n",
      "Epoch 345/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7760430592.0000 - val_loss: 8365728768.0000\n",
      "Epoch 346/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7189112320.0000 - val_loss: 8475551744.0000\n",
      "Epoch 347/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7274070016.0000 - val_loss: 8271484928.0000\n",
      "Epoch 348/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7327310848.0000 - val_loss: 10304322560.0000\n",
      "Epoch 349/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7286180864.0000 - val_loss: 8672010240.0000\n",
      "Epoch 350/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7134208000.0000 - val_loss: 8877976576.0000\n",
      "Epoch 351/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7440979968.0000 - val_loss: 8174852096.0000\n",
      "Epoch 352/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7012445184.0000 - val_loss: 8383826432.0000\n",
      "Epoch 353/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7266239488.0000 - val_loss: 8946700288.0000\n",
      "Epoch 354/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6966737920.0000 - val_loss: 10012744704.0000\n",
      "Epoch 355/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7275964928.0000 - val_loss: 9209064448.0000\n",
      "Epoch 356/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7247193600.0000 - val_loss: 8207368704.0000\n",
      "Epoch 357/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7134330368.0000 - val_loss: 8195776512.0000\n",
      "Epoch 358/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7049261056.0000 - val_loss: 8460408832.0000\n",
      "Epoch 359/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7216155648.0000 - val_loss: 8262230528.0000\n",
      "Epoch 360/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7184990208.0000 - val_loss: 9018224640.0000\n",
      "Epoch 361/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7208488448.0000 - val_loss: 8252689920.0000\n",
      "Epoch 362/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7066463232.0000 - val_loss: 8273243648.0000\n",
      "Epoch 363/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7026903040.0000 - val_loss: 8575974400.0000\n",
      "Epoch 364/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7344132608.0000 - val_loss: 8498174464.0000\n",
      "Epoch 365/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7189601280.0000 - val_loss: 8394225152.0000\n",
      "Epoch 366/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7165738496.0000 - val_loss: 8236821504.0000\n",
      "Epoch 367/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7051405824.0000 - val_loss: 8225874944.0000\n",
      "Epoch 368/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7182536704.0000 - val_loss: 8494638080.0000\n",
      "Epoch 369/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7257898496.0000 - val_loss: 9128465408.0000\n",
      "Epoch 370/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7031628800.0000 - val_loss: 9939769344.0000\n",
      "Epoch 371/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7519863296.0000 - val_loss: 8267191808.0000\n",
      "Epoch 372/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7600189952.0000 - val_loss: 8359053824.0000\n",
      "Epoch 373/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7254993920.0000 - val_loss: 8352543744.0000\n",
      "Epoch 374/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7106607616.0000 - val_loss: 9195170816.0000\n",
      "Epoch 375/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6914655232.0000 - val_loss: 8466805760.0000\n",
      "Epoch 376/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7282820096.0000 - val_loss: 8671068160.0000\n",
      "Epoch 377/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7169923072.0000 - val_loss: 10383539200.0000\n",
      "Epoch 378/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7785387520.0000 - val_loss: 8228520960.0000\n",
      "Epoch 379/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7368390144.0000 - val_loss: 8247421440.0000\n",
      "Epoch 380/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6918846464.0000 - val_loss: 10686124032.0000\n",
      "Epoch 381/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7533369856.0000 - val_loss: 8793449472.0000\n",
      "Epoch 382/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7093399552.0000 - val_loss: 8685846528.0000\n",
      "Epoch 383/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6976018944.0000 - val_loss: 8291006464.0000\n",
      "Epoch 384/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7648696320.0000 - val_loss: 8537079808.0000\n",
      "Epoch 385/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6917020672.0000 - val_loss: 8318423040.0000\n",
      "Epoch 386/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6992636416.0000 - val_loss: 8261205504.0000\n",
      "Epoch 387/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7004564480.0000 - val_loss: 8279361024.0000\n",
      "Epoch 388/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7318235648.0000 - val_loss: 8362805248.0000\n",
      "Epoch 389/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6976516608.0000 - val_loss: 11784181760.0000\n",
      "Epoch 390/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7228063744.0000 - val_loss: 9247970304.0000\n",
      "Epoch 391/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7321751040.0000 - val_loss: 9538110464.0000\n",
      "Epoch 392/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6944415744.0000 - val_loss: 8369190400.0000\n",
      "Epoch 393/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7549480448.0000 - val_loss: 8358878208.0000\n",
      "Epoch 394/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6786535936.0000 - val_loss: 8963141632.0000\n",
      "Epoch 395/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7689703936.0000 - val_loss: 9169867776.0000\n",
      "Epoch 396/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6955698688.0000 - val_loss: 8256203776.0000\n",
      "Epoch 397/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7661962240.0000 - val_loss: 12333939712.0000\n",
      "Epoch 398/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7344508416.0000 - val_loss: 8682715136.0000\n",
      "Epoch 399/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7334188032.0000 - val_loss: 8253035008.0000\n",
      "Epoch 400/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7078680064.0000 - val_loss: 8426941440.0000\n",
      "Epoch 401/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6800537600.0000 - val_loss: 8298137600.0000\n",
      "Epoch 402/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7200855552.0000 - val_loss: 9019438080.0000\n",
      "Epoch 403/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6903680000.0000 - val_loss: 8800541696.0000\n",
      "Epoch 404/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7115054080.0000 - val_loss: 8520072192.0000\n",
      "Epoch 405/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7260003328.0000 - val_loss: 8521991168.0000\n",
      "Epoch 406/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6946500096.0000 - val_loss: 8491867648.0000\n",
      "Epoch 407/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6870131712.0000 - val_loss: 8501176832.0000\n",
      "Epoch 408/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6857466368.0000 - val_loss: 10023797760.0000\n",
      "Epoch 409/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7264388608.0000 - val_loss: 8242386432.0000\n",
      "Epoch 410/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7130760704.0000 - val_loss: 8364233216.0000\n",
      "Epoch 411/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6797795840.0000 - val_loss: 8446806016.0000\n",
      "Epoch 412/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6692464640.0000 - val_loss: 8507378176.0000\n",
      "Epoch 413/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7191598080.0000 - val_loss: 8563191808.0000\n",
      "Epoch 414/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7069655552.0000 - val_loss: 8396683776.0000\n",
      "Epoch 415/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6989411328.0000 - val_loss: 8879478784.0000\n",
      "Epoch 416/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6899843584.0000 - val_loss: 8480453632.0000\n",
      "Epoch 417/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6753064448.0000 - val_loss: 8300834304.0000\n",
      "Epoch 418/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6922326016.0000 - val_loss: 8464051712.0000\n",
      "Epoch 419/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7175040000.0000 - val_loss: 8668379136.0000\n",
      "Epoch 420/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6943512576.0000 - val_loss: 8456845824.0000\n",
      "Epoch 421/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7557981696.0000 - val_loss: 8716560384.0000\n",
      "Epoch 422/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6910598144.0000 - val_loss: 8973746176.0000\n",
      "Epoch 423/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6863420416.0000 - val_loss: 9542285312.0000\n",
      "Epoch 424/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6965989888.0000 - val_loss: 8602775552.0000\n",
      "Epoch 425/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6855674368.0000 - val_loss: 8536109568.0000\n",
      "Epoch 426/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7359242752.0000 - val_loss: 8333167616.0000\n",
      "Epoch 427/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6795176960.0000 - val_loss: 8607186944.0000\n",
      "Epoch 428/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6968453632.0000 - val_loss: 8239874048.0000\n",
      "Epoch 429/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7272882176.0000 - val_loss: 8678062080.0000\n",
      "Epoch 430/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6754323968.0000 - val_loss: 8548127744.0000\n",
      "Epoch 431/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6594902016.0000 - val_loss: 9178270720.0000\n",
      "Epoch 432/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6916150272.0000 - val_loss: 8553268736.0000\n",
      "Epoch 433/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6819979264.0000 - val_loss: 10327100416.0000\n",
      "Epoch 434/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6716841472.0000 - val_loss: 8924011520.0000\n",
      "Epoch 435/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6710090240.0000 - val_loss: 8237433856.0000\n",
      "Epoch 436/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6815766016.0000 - val_loss: 8646274048.0000\n",
      "Epoch 437/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7143746048.0000 - val_loss: 8364254720.0000\n",
      "Epoch 438/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7326608384.0000 - val_loss: 8306756608.0000\n",
      "Epoch 439/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6908977152.0000 - val_loss: 8927107072.0000\n",
      "Epoch 440/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6806222848.0000 - val_loss: 8774176768.0000\n",
      "Epoch 441/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6869430272.0000 - val_loss: 8817413120.0000\n",
      "Epoch 442/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6953862656.0000 - val_loss: 9517775872.0000\n",
      "Epoch 443/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7002848768.0000 - val_loss: 8421641216.0000\n",
      "Epoch 444/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6839844352.0000 - val_loss: 8558061056.0000\n",
      "Epoch 445/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7122106880.0000 - val_loss: 9502830592.0000\n",
      "Epoch 446/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6901011456.0000 - val_loss: 8610690048.0000\n",
      "Epoch 447/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7151947776.0000 - val_loss: 8683072512.0000\n",
      "Epoch 448/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6733787648.0000 - val_loss: 8884289536.0000\n",
      "Epoch 449/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6894658048.0000 - val_loss: 8334696960.0000\n",
      "Epoch 450/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6853624320.0000 - val_loss: 8265670144.0000\n",
      "Epoch 451/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6641346048.0000 - val_loss: 8353457664.0000\n",
      "Epoch 452/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6888627200.0000 - val_loss: 8795982848.0000\n",
      "Epoch 453/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7188936704.0000 - val_loss: 11839520768.0000\n",
      "Epoch 454/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6706944512.0000 - val_loss: 8465143808.0000\n",
      "Epoch 455/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6775314432.0000 - val_loss: 8594735104.0000\n",
      "Epoch 456/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7491063808.0000 - val_loss: 8462565888.0000\n",
      "Epoch 457/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6749950464.0000 - val_loss: 9709691904.0000\n",
      "Epoch 458/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6666364416.0000 - val_loss: 9766178816.0000\n",
      "Epoch 459/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6918253056.0000 - val_loss: 8456351232.0000\n",
      "Epoch 460/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6591750144.0000 - val_loss: 8600711168.0000\n",
      "Epoch 461/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6893564416.0000 - val_loss: 8370328064.0000\n",
      "Epoch 462/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6841986560.0000 - val_loss: 9355959296.0000\n",
      "Epoch 463/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6640073728.0000 - val_loss: 9957573632.0000\n",
      "Epoch 464/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6710989312.0000 - val_loss: 8519511040.0000\n",
      "Epoch 465/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7043505664.0000 - val_loss: 8429527552.0000\n",
      "Epoch 466/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6640373248.0000 - val_loss: 8282423296.0000\n",
      "Epoch 467/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7293590528.0000 - val_loss: 8680605696.0000\n",
      "Epoch 468/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6814120960.0000 - val_loss: 9263680512.0000\n",
      "Epoch 469/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6814197760.0000 - val_loss: 9232525312.0000\n",
      "Epoch 470/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6945288192.0000 - val_loss: 8417690624.0000\n",
      "Epoch 471/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6609800192.0000 - val_loss: 9603698688.0000\n",
      "Epoch 472/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6714789376.0000 - val_loss: 9809031168.0000\n",
      "Epoch 473/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7125345792.0000 - val_loss: 8947962880.0000\n",
      "Epoch 474/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6982063616.0000 - val_loss: 8918029312.0000\n",
      "Epoch 475/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6549178368.0000 - val_loss: 8716264448.0000\n",
      "Epoch 476/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6698065408.0000 - val_loss: 8828780544.0000\n",
      "Epoch 477/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6768665600.0000 - val_loss: 8368771584.0000\n",
      "Epoch 478/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6477795328.0000 - val_loss: 8812562432.0000\n",
      "Epoch 479/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6692933632.0000 - val_loss: 8474376704.0000\n",
      "Epoch 480/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6508986880.0000 - val_loss: 8448439808.0000\n",
      "Epoch 481/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6749270016.0000 - val_loss: 8772082688.0000\n",
      "Epoch 482/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6924942336.0000 - val_loss: 8701961216.0000\n",
      "Epoch 483/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6875399168.0000 - val_loss: 8507000832.0000\n",
      "Epoch 484/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6503891456.0000 - val_loss: 9008527360.0000\n",
      "Epoch 485/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6476120576.0000 - val_loss: 8886175744.0000\n",
      "Epoch 486/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7096406528.0000 - val_loss: 8620355584.0000\n",
      "Epoch 487/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7112601600.0000 - val_loss: 8641094656.0000\n",
      "Epoch 488/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6715809280.0000 - val_loss: 8977689600.0000\n",
      "Epoch 489/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6484454912.0000 - val_loss: 8670331904.0000\n",
      "Epoch 490/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6929864704.0000 - val_loss: 9418613760.0000\n",
      "Epoch 491/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6856443392.0000 - val_loss: 8691982336.0000\n",
      "Epoch 492/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6565530112.0000 - val_loss: 8797003776.0000\n",
      "Epoch 493/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6467411456.0000 - val_loss: 9448770560.0000\n",
      "Epoch 494/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7354327552.0000 - val_loss: 8563112448.0000\n",
      "Epoch 495/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6698071040.0000 - val_loss: 8471903744.0000\n",
      "Epoch 496/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6669914624.0000 - val_loss: 8943168512.0000\n",
      "Epoch 497/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7489698304.0000 - val_loss: 9019301888.0000\n",
      "Epoch 498/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6697149440.0000 - val_loss: 9534159872.0000\n",
      "Epoch 499/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6685223424.0000 - val_loss: 8443750912.0000\n",
      "Epoch 500/800\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 6608988672.0000 - val_loss: 8715839488.0000\n",
      "Epoch 501/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6710980608.0000 - val_loss: 9683645440.0000\n",
      "Epoch 502/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6610919936.0000 - val_loss: 8715258880.0000\n",
      "Epoch 503/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6569353216.0000 - val_loss: 8916228096.0000\n",
      "Epoch 504/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6796251136.0000 - val_loss: 8671722496.0000\n",
      "Epoch 505/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6479730688.0000 - val_loss: 8767129600.0000\n",
      "Epoch 506/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6873427968.0000 - val_loss: 8854460416.0000\n",
      "Epoch 507/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6397261312.0000 - val_loss: 9302562816.0000\n",
      "Epoch 508/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6934169088.0000 - val_loss: 9476541440.0000\n",
      "Epoch 509/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6484094464.0000 - val_loss: 8742728704.0000\n",
      "Epoch 510/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6482278400.0000 - val_loss: 9615480832.0000\n",
      "Epoch 511/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6466454016.0000 - val_loss: 8739135488.0000\n",
      "Epoch 512/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6576685568.0000 - val_loss: 8583609856.0000\n",
      "Epoch 513/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6786738688.0000 - val_loss: 8392801280.0000\n",
      "Epoch 514/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6298648064.0000 - val_loss: 8545814528.0000\n",
      "Epoch 515/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6528291840.0000 - val_loss: 8762065920.0000\n",
      "Epoch 516/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6746698752.0000 - val_loss: 8754014208.0000\n",
      "Epoch 517/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6649931264.0000 - val_loss: 9712550912.0000\n",
      "Epoch 518/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6628633088.0000 - val_loss: 9606450176.0000\n",
      "Epoch 519/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6435718144.0000 - val_loss: 8497442816.0000\n",
      "Epoch 520/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6734496768.0000 - val_loss: 9232115712.0000\n",
      "Epoch 521/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6814839296.0000 - val_loss: 8802061312.0000\n",
      "Epoch 522/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6536611840.0000 - val_loss: 9244689408.0000\n",
      "Epoch 523/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6512277504.0000 - val_loss: 8952402944.0000\n",
      "Epoch 524/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6691298304.0000 - val_loss: 10625881088.0000\n",
      "Epoch 525/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6395752960.0000 - val_loss: 8604849152.0000\n",
      "Epoch 526/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6595081728.0000 - val_loss: 9644696576.0000\n",
      "Epoch 527/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6599624704.0000 - val_loss: 8538496000.0000\n",
      "Epoch 528/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6425332736.0000 - val_loss: 8971286528.0000\n",
      "Epoch 529/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6777263104.0000 - val_loss: 9130276864.0000\n",
      "Epoch 530/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6786335744.0000 - val_loss: 8902834176.0000\n",
      "Epoch 531/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7173763584.0000 - val_loss: 8694445056.0000\n",
      "Epoch 532/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6330008064.0000 - val_loss: 9124937728.0000\n",
      "Epoch 533/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6591411200.0000 - val_loss: 8447483392.0000\n",
      "Epoch 534/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6721875968.0000 - val_loss: 8770125824.0000\n",
      "Epoch 535/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6314352640.0000 - val_loss: 8552055296.0000\n",
      "Epoch 536/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6476478976.0000 - val_loss: 9028754432.0000\n",
      "Epoch 537/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6462892032.0000 - val_loss: 8813861888.0000\n",
      "Epoch 538/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6512867840.0000 - val_loss: 8664304640.0000\n",
      "Epoch 539/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6422659072.0000 - val_loss: 8591660032.0000\n",
      "Epoch 540/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6250402304.0000 - val_loss: 8860345344.0000\n",
      "Epoch 541/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6449353728.0000 - val_loss: 8644509696.0000\n",
      "Epoch 542/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6348311040.0000 - val_loss: 8632556544.0000\n",
      "Epoch 543/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6548660224.0000 - val_loss: 8585015808.0000\n",
      "Epoch 544/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6319547904.0000 - val_loss: 8581735424.0000\n",
      "Epoch 545/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6769402368.0000 - val_loss: 9569444864.0000\n",
      "Epoch 546/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7155215360.0000 - val_loss: 8579654144.0000\n",
      "Epoch 547/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6377561600.0000 - val_loss: 8417823744.0000\n",
      "Epoch 548/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6554648064.0000 - val_loss: 9655812096.0000\n",
      "Epoch 549/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6525847040.0000 - val_loss: 8608535552.0000\n",
      "Epoch 550/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6424080896.0000 - val_loss: 8565589504.0000\n",
      "Epoch 551/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6317458944.0000 - val_loss: 8427073024.0000\n",
      "Epoch 552/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6633051136.0000 - val_loss: 9339485184.0000\n",
      "Epoch 553/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6407933952.0000 - val_loss: 9165288448.0000\n",
      "Epoch 554/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6459279872.0000 - val_loss: 8750669824.0000\n",
      "Epoch 555/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6860212736.0000 - val_loss: 9766842368.0000\n",
      "Epoch 556/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6555850240.0000 - val_loss: 8694043648.0000\n",
      "Epoch 557/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6213262336.0000 - val_loss: 8706496512.0000\n",
      "Epoch 558/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6566912512.0000 - val_loss: 9382390784.0000\n",
      "Epoch 559/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6399349760.0000 - val_loss: 8716512256.0000\n",
      "Epoch 560/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6167776256.0000 - val_loss: 8847164416.0000\n",
      "Epoch 561/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6283322368.0000 - val_loss: 8906520576.0000\n",
      "Epoch 562/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6826078720.0000 - val_loss: 8570699264.0000\n",
      "Epoch 563/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6379966976.0000 - val_loss: 8992578560.0000\n",
      "Epoch 564/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6490960896.0000 - val_loss: 9056564224.0000\n",
      "Epoch 565/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6328971776.0000 - val_loss: 8490331136.0000\n",
      "Epoch 566/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6495259648.0000 - val_loss: 8691964928.0000\n",
      "Epoch 567/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6723881984.0000 - val_loss: 8730454016.0000\n",
      "Epoch 568/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6364148224.0000 - val_loss: 9014885376.0000\n",
      "Epoch 569/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6486329344.0000 - val_loss: 8822743040.0000\n",
      "Epoch 570/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6159732736.0000 - val_loss: 8641247232.0000\n",
      "Epoch 571/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6318530048.0000 - val_loss: 8556992512.0000\n",
      "Epoch 572/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6782747136.0000 - val_loss: 10030921728.0000\n",
      "Epoch 573/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6500063232.0000 - val_loss: 8510709248.0000\n",
      "Epoch 574/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7232512000.0000 - val_loss: 8928020480.0000\n",
      "Epoch 575/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6194338816.0000 - val_loss: 8770094080.0000\n",
      "Epoch 576/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6055422976.0000 - val_loss: 8653889536.0000\n",
      "Epoch 577/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6278470144.0000 - val_loss: 8708525056.0000\n",
      "Epoch 578/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6294456320.0000 - val_loss: 9595279360.0000\n",
      "Epoch 579/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6447903232.0000 - val_loss: 9129113600.0000\n",
      "Epoch 580/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6207064576.0000 - val_loss: 9068282880.0000\n",
      "Epoch 581/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6187212800.0000 - val_loss: 8738408448.0000\n",
      "Epoch 582/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6218078720.0000 - val_loss: 9249601536.0000\n",
      "Epoch 583/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6265337856.0000 - val_loss: 8724302848.0000\n",
      "Epoch 584/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6399185408.0000 - val_loss: 8538113536.0000\n",
      "Epoch 585/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6106348032.0000 - val_loss: 8597401600.0000\n",
      "Epoch 586/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6269361152.0000 - val_loss: 9333645312.0000\n",
      "Epoch 587/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6868028416.0000 - val_loss: 10125339648.0000\n",
      "Epoch 588/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6657407488.0000 - val_loss: 9085393920.0000\n",
      "Epoch 589/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6668878848.0000 - val_loss: 10950355968.0000\n",
      "Epoch 590/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6508090880.0000 - val_loss: 8638706688.0000\n",
      "Epoch 591/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5947422720.0000 - val_loss: 8790740992.0000\n",
      "Epoch 592/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6140258304.0000 - val_loss: 9469430784.0000\n",
      "Epoch 593/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6214113792.0000 - val_loss: 9259761664.0000\n",
      "Epoch 594/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6763660288.0000 - val_loss: 11576727552.0000\n",
      "Epoch 595/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6329875968.0000 - val_loss: 10175710208.0000\n",
      "Epoch 596/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6433883136.0000 - val_loss: 8929018880.0000\n",
      "Epoch 597/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5931749376.0000 - val_loss: 8935719936.0000\n",
      "Epoch 598/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6059115008.0000 - val_loss: 8941416448.0000\n",
      "Epoch 599/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6147436544.0000 - val_loss: 8761868288.0000\n",
      "Epoch 600/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6379241984.0000 - val_loss: 9769738240.0000\n",
      "Epoch 601/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6215817728.0000 - val_loss: 8644445184.0000\n",
      "Epoch 602/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5986187776.0000 - val_loss: 8555115520.0000\n",
      "Epoch 603/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6534087168.0000 - val_loss: 10529965056.0000\n",
      "Epoch 604/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6426044416.0000 - val_loss: 8516467200.0000\n",
      "Epoch 605/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6562888192.0000 - val_loss: 8588415488.0000\n",
      "Epoch 606/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6058519552.0000 - val_loss: 8710432768.0000\n",
      "Epoch 607/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6144939520.0000 - val_loss: 9388712960.0000\n",
      "Epoch 608/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6230793728.0000 - val_loss: 8548562432.0000\n",
      "Epoch 609/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6206206976.0000 - val_loss: 13183974400.0000\n",
      "Epoch 610/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6193548800.0000 - val_loss: 8867976192.0000\n",
      "Epoch 611/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6006182400.0000 - val_loss: 9063159808.0000\n",
      "Epoch 612/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6050723328.0000 - val_loss: 9185661952.0000\n",
      "Epoch 613/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6335006720.0000 - val_loss: 9371890688.0000\n",
      "Epoch 614/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6368215552.0000 - val_loss: 8742341632.0000\n",
      "Epoch 615/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6264010240.0000 - val_loss: 8805188608.0000\n",
      "Epoch 616/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5943860736.0000 - val_loss: 9377028096.0000\n",
      "Epoch 617/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6301547520.0000 - val_loss: 9447062528.0000\n",
      "Epoch 618/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6516196352.0000 - val_loss: 9435800576.0000\n",
      "Epoch 619/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6121596416.0000 - val_loss: 8907613184.0000\n",
      "Epoch 620/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6026268160.0000 - val_loss: 8866443264.0000\n",
      "Epoch 621/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6629832192.0000 - val_loss: 9994404864.0000\n",
      "Epoch 622/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6002994176.0000 - val_loss: 8910814208.0000\n",
      "Epoch 623/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6012291072.0000 - val_loss: 10248010752.0000\n",
      "Epoch 624/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6033810944.0000 - val_loss: 9618275328.0000\n",
      "Epoch 625/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5876431872.0000 - val_loss: 8724366336.0000\n",
      "Epoch 626/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6194888192.0000 - val_loss: 8596672512.0000\n",
      "Epoch 627/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6036019712.0000 - val_loss: 8860326912.0000\n",
      "Epoch 628/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6010958848.0000 - val_loss: 9430184960.0000\n",
      "Epoch 629/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5876584448.0000 - val_loss: 8713394176.0000\n",
      "Epoch 630/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6281361408.0000 - val_loss: 10767064064.0000\n",
      "Epoch 631/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6217748992.0000 - val_loss: 9565123584.0000\n",
      "Epoch 632/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5968013312.0000 - val_loss: 8729249792.0000\n",
      "Epoch 633/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6215767040.0000 - val_loss: 8863249408.0000\n",
      "Epoch 634/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6119421952.0000 - val_loss: 9679551488.0000\n",
      "Epoch 635/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6566758400.0000 - val_loss: 9637449728.0000\n",
      "Epoch 636/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6179977728.0000 - val_loss: 9262318592.0000\n",
      "Epoch 637/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5892340736.0000 - val_loss: 9174758400.0000\n",
      "Epoch 638/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5871278080.0000 - val_loss: 9923812352.0000\n",
      "Epoch 639/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6044128768.0000 - val_loss: 8945426432.0000\n",
      "Epoch 640/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5850643456.0000 - val_loss: 8760444928.0000\n",
      "Epoch 641/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5931036672.0000 - val_loss: 9538114560.0000\n",
      "Epoch 642/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6434257408.0000 - val_loss: 8792388608.0000\n",
      "Epoch 643/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6220045312.0000 - val_loss: 9627854848.0000\n",
      "Epoch 644/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6124754432.0000 - val_loss: 8989182976.0000\n",
      "Epoch 645/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5995207168.0000 - val_loss: 9952464896.0000\n",
      "Epoch 646/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5889369088.0000 - val_loss: 10172794880.0000\n",
      "Epoch 647/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6118881280.0000 - val_loss: 8956335104.0000\n",
      "Epoch 648/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6168151552.0000 - val_loss: 11209385984.0000\n",
      "Epoch 649/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6368603648.0000 - val_loss: 9033290752.0000\n",
      "Epoch 650/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5816189440.0000 - val_loss: 8758982656.0000\n",
      "Epoch 651/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6066618880.0000 - val_loss: 8873805824.0000\n",
      "Epoch 652/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6427698176.0000 - val_loss: 9596480512.0000\n",
      "Epoch 653/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5994731008.0000 - val_loss: 8874056704.0000\n",
      "Epoch 654/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5808777216.0000 - val_loss: 8797090816.0000\n",
      "Epoch 655/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5879222784.0000 - val_loss: 8862599168.0000\n",
      "Epoch 656/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5959045120.0000 - val_loss: 8834201600.0000\n",
      "Epoch 657/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6122002432.0000 - val_loss: 9774309376.0000\n",
      "Epoch 658/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5991104512.0000 - val_loss: 8924634112.0000\n",
      "Epoch 659/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6316683776.0000 - val_loss: 8959207424.0000\n",
      "Epoch 660/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5696757760.0000 - val_loss: 10213149696.0000\n",
      "Epoch 661/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5861464064.0000 - val_loss: 9295001600.0000\n",
      "Epoch 662/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6015806976.0000 - val_loss: 8858909696.0000\n",
      "Epoch 663/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6094559232.0000 - val_loss: 9706866688.0000\n",
      "Epoch 664/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5973928960.0000 - val_loss: 8746831872.0000\n",
      "Epoch 665/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6164948480.0000 - val_loss: 8892409856.0000\n",
      "Epoch 666/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5892221952.0000 - val_loss: 8877140992.0000\n",
      "Epoch 667/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5983991296.0000 - val_loss: 8784807936.0000\n",
      "Epoch 668/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5999511040.0000 - val_loss: 9342034944.0000\n",
      "Epoch 669/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6166119936.0000 - val_loss: 10760848384.0000\n",
      "Epoch 670/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5922782208.0000 - val_loss: 9055689728.0000\n",
      "Epoch 671/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6048515072.0000 - val_loss: 9425618944.0000\n",
      "Epoch 672/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6208215040.0000 - val_loss: 9118283776.0000\n",
      "Epoch 673/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5928714752.0000 - val_loss: 10095202304.0000\n",
      "Epoch 674/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 6145854976.0000 - val_loss: 9250591744.0000\n",
      "Epoch 675/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5574743552.0000 - val_loss: 9110421504.0000\n",
      "Epoch 676/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5755601920.0000 - val_loss: 8881599488.0000\n",
      "Epoch 677/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5717144576.0000 - val_loss: 10288659456.0000\n",
      "Epoch 678/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6036341248.0000 - val_loss: 11056181248.0000\n",
      "Epoch 679/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6081011200.0000 - val_loss: 8802820096.0000\n",
      "Epoch 680/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5658632192.0000 - val_loss: 10389245952.0000\n",
      "Epoch 681/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5749717504.0000 - val_loss: 8793448448.0000\n",
      "Epoch 682/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5705677824.0000 - val_loss: 9152129024.0000\n",
      "Epoch 683/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5695847936.0000 - val_loss: 9413311488.0000\n",
      "Epoch 684/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5731465728.0000 - val_loss: 10019755008.0000\n",
      "Epoch 685/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6074963456.0000 - val_loss: 9230309376.0000\n",
      "Epoch 686/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5652124672.0000 - val_loss: 8859592704.0000\n",
      "Epoch 687/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5741326848.0000 - val_loss: 9046943744.0000\n",
      "Epoch 688/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5724591104.0000 - val_loss: 10172291072.0000\n",
      "Epoch 689/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5943636480.0000 - val_loss: 9598512128.0000\n",
      "Epoch 690/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6125725696.0000 - val_loss: 9211754496.0000\n",
      "Epoch 691/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5715207680.0000 - val_loss: 9251805184.0000\n",
      "Epoch 692/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5707717120.0000 - val_loss: 9677245440.0000\n",
      "Epoch 693/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6047384576.0000 - val_loss: 9004602368.0000\n",
      "Epoch 694/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6110423040.0000 - val_loss: 8959782912.0000\n",
      "Epoch 695/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5726500352.0000 - val_loss: 9106579456.0000\n",
      "Epoch 696/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5601564160.0000 - val_loss: 8745777152.0000\n",
      "Epoch 697/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5740748800.0000 - val_loss: 9218709504.0000\n",
      "Epoch 698/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5737236480.0000 - val_loss: 8791925760.0000\n",
      "Epoch 699/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6142271488.0000 - val_loss: 10105047040.0000\n",
      "Epoch 700/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5864084480.0000 - val_loss: 8853240832.0000\n",
      "Epoch 701/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5986821120.0000 - val_loss: 10076605440.0000\n",
      "Epoch 702/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5776795648.0000 - val_loss: 9995878400.0000\n",
      "Epoch 703/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5764643840.0000 - val_loss: 10380756992.0000\n",
      "Epoch 704/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5913443328.0000 - val_loss: 8876924928.0000\n",
      "Epoch 705/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5939112448.0000 - val_loss: 8750807040.0000\n",
      "Epoch 706/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6186030080.0000 - val_loss: 8739144704.0000\n",
      "Epoch 707/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5691738624.0000 - val_loss: 9773731840.0000\n",
      "Epoch 708/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5618430464.0000 - val_loss: 9041564672.0000\n",
      "Epoch 709/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5497633792.0000 - val_loss: 9570636800.0000\n",
      "Epoch 710/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5694735872.0000 - val_loss: 9465322496.0000\n",
      "Epoch 711/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5692373504.0000 - val_loss: 9502342144.0000\n",
      "Epoch 712/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5476319744.0000 - val_loss: 8850236416.0000\n",
      "Epoch 713/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5559465472.0000 - val_loss: 10421784576.0000\n",
      "Epoch 714/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5612783616.0000 - val_loss: 9228655616.0000\n",
      "Epoch 715/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5974495744.0000 - val_loss: 8851702784.0000\n",
      "Epoch 716/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5734410752.0000 - val_loss: 9091716096.0000\n",
      "Epoch 717/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5659610624.0000 - val_loss: 9045568512.0000\n",
      "Epoch 718/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5705693184.0000 - val_loss: 9408412672.0000\n",
      "Epoch 719/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5759581696.0000 - val_loss: 9071361024.0000\n",
      "Epoch 720/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5985658368.0000 - val_loss: 9305640960.0000\n",
      "Epoch 721/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5453827584.0000 - val_loss: 9131541504.0000\n",
      "Epoch 722/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6194169856.0000 - val_loss: 9221753856.0000\n",
      "Epoch 723/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5802676736.0000 - val_loss: 9305976832.0000\n",
      "Epoch 724/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5599154688.0000 - val_loss: 9123694592.0000\n",
      "Epoch 725/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5627017728.0000 - val_loss: 9041307648.0000\n",
      "Epoch 726/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5408467968.0000 - val_loss: 9439192064.0000\n",
      "Epoch 727/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5454724608.0000 - val_loss: 9834722304.0000\n",
      "Epoch 728/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5924070400.0000 - val_loss: 9244446720.0000\n",
      "Epoch 729/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5596743168.0000 - val_loss: 9101478912.0000\n",
      "Epoch 730/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5587259392.0000 - val_loss: 10207108096.0000\n",
      "Epoch 731/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5820853248.0000 - val_loss: 8896509952.0000\n",
      "Epoch 732/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5378368512.0000 - val_loss: 9447645184.0000\n",
      "Epoch 733/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5680413696.0000 - val_loss: 8944154624.0000\n",
      "Epoch 734/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5255309312.0000 - val_loss: 9068831744.0000\n",
      "Epoch 735/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5788479488.0000 - val_loss: 11921632256.0000\n",
      "Epoch 736/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 6063270912.0000 - val_loss: 9060112384.0000\n",
      "Epoch 737/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5486902272.0000 - val_loss: 9421802496.0000\n",
      "Epoch 738/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5689609216.0000 - val_loss: 9146134528.0000\n",
      "Epoch 739/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5438464512.0000 - val_loss: 9380886528.0000\n",
      "Epoch 740/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5509605888.0000 - val_loss: 9096100864.0000\n",
      "Epoch 741/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5331866112.0000 - val_loss: 10011335680.0000\n",
      "Epoch 742/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5833801216.0000 - val_loss: 9259385856.0000\n",
      "Epoch 743/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5329295872.0000 - val_loss: 8987335680.0000\n",
      "Epoch 744/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5360554496.0000 - val_loss: 9088045056.0000\n",
      "Epoch 745/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5779827712.0000 - val_loss: 9105963008.0000\n",
      "Epoch 746/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5651042816.0000 - val_loss: 9514783744.0000\n",
      "Epoch 747/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5882422272.0000 - val_loss: 9547077632.0000\n",
      "Epoch 748/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5394218496.0000 - val_loss: 9474644992.0000\n",
      "Epoch 749/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5965748224.0000 - val_loss: 9114845184.0000\n",
      "Epoch 750/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5273376256.0000 - val_loss: 9591760896.0000\n",
      "Epoch 751/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5283740160.0000 - val_loss: 9173316608.0000\n",
      "Epoch 752/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5691066880.0000 - val_loss: 9629410304.0000\n",
      "Epoch 753/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5598429696.0000 - val_loss: 9298539520.0000\n",
      "Epoch 754/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5392698880.0000 - val_loss: 9306983424.0000\n",
      "Epoch 755/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5536712704.0000 - val_loss: 11343250432.0000\n",
      "Epoch 756/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5766614016.0000 - val_loss: 9069326336.0000\n",
      "Epoch 757/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5405905920.0000 - val_loss: 9282368512.0000\n",
      "Epoch 758/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5629149696.0000 - val_loss: 9669638144.0000\n",
      "Epoch 759/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5865381888.0000 - val_loss: 9160792064.0000\n",
      "Epoch 760/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5459757568.0000 - val_loss: 13037999104.0000\n",
      "Epoch 761/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5785341952.0000 - val_loss: 9110995968.0000\n",
      "Epoch 762/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5434108928.0000 - val_loss: 9524866048.0000\n",
      "Epoch 763/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5330906112.0000 - val_loss: 9226798080.0000\n",
      "Epoch 764/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5421007872.0000 - val_loss: 10077927424.0000\n",
      "Epoch 765/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5582387200.0000 - val_loss: 9844662272.0000\n",
      "Epoch 766/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5631646720.0000 - val_loss: 9681760256.0000\n",
      "Epoch 767/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5376103936.0000 - val_loss: 9272609792.0000\n",
      "Epoch 768/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5659634176.0000 - val_loss: 10038407168.0000\n",
      "Epoch 769/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5567851008.0000 - val_loss: 9044082688.0000\n",
      "Epoch 770/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5368931840.0000 - val_loss: 9605649408.0000\n",
      "Epoch 771/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5430818304.0000 - val_loss: 9249647616.0000\n",
      "Epoch 772/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5365649408.0000 - val_loss: 10325175296.0000\n",
      "Epoch 773/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5868954112.0000 - val_loss: 9389528064.0000\n",
      "Epoch 774/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5469130240.0000 - val_loss: 11286723584.0000\n",
      "Epoch 775/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5395671040.0000 - val_loss: 9163882496.0000\n",
      "Epoch 776/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5180420096.0000 - val_loss: 9331962880.0000\n",
      "Epoch 777/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5443372544.0000 - val_loss: 10327724032.0000\n",
      "Epoch 778/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5425931264.0000 - val_loss: 10473306112.0000\n",
      "Epoch 779/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5492931584.0000 - val_loss: 9622834176.0000\n",
      "Epoch 780/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5143831040.0000 - val_loss: 9167956992.0000\n",
      "Epoch 781/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5415734272.0000 - val_loss: 9696317440.0000\n",
      "Epoch 782/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5507212800.0000 - val_loss: 9701578752.0000\n",
      "Epoch 783/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5094329344.0000 - val_loss: 9074324480.0000\n",
      "Epoch 784/800\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5158408704.0000 - val_loss: 9726694400.0000\n",
      "Epoch 785/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5392819200.0000 - val_loss: 9415848960.0000\n",
      "Epoch 786/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5553412096.0000 - val_loss: 9316989952.0000\n",
      "Epoch 787/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5523002368.0000 - val_loss: 9344052224.0000\n",
      "Epoch 788/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5096102400.0000 - val_loss: 12065370112.0000\n",
      "Epoch 789/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5931439104.0000 - val_loss: 9396156416.0000\n",
      "Epoch 790/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5129106432.0000 - val_loss: 9167964160.0000\n",
      "Epoch 791/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5025301504.0000 - val_loss: 9328756736.0000\n",
      "Epoch 792/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5705798656.0000 - val_loss: 9226901504.0000\n",
      "Epoch 793/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5650366464.0000 - val_loss: 9482386432.0000\n",
      "Epoch 794/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5364401152.0000 - val_loss: 9292374016.0000\n",
      "Epoch 795/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5106281472.0000 - val_loss: 9532740608.0000\n",
      "Epoch 796/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5264953856.0000 - val_loss: 9055203328.0000\n",
      "Epoch 797/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 4961036800.0000 - val_loss: 9625773056.0000\n",
      "Epoch 798/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5154737152.0000 - val_loss: 10035346432.0000\n",
      "Epoch 799/800\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 5232496640.0000 - val_loss: 9676023808.0000\n",
      "Epoch 800/800\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 5106446848.0000 - val_loss: 10426935296.0000\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 81)                6642      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 162)               13284     \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 324)               52812     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 648)               210600    \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 324)               210276    \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 162)               52650     \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 81)                13203     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 20)                1640      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 561,128\n",
      "Trainable params: 561,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=800)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c304097",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc9f3898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77da5c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c7178b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "24b11aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109596411446791"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d8011028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.956189351341689e+19"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "590c4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7357b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
